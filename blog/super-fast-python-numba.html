<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.4.0/styles/github-dark.min.css"/><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/35cab027331baf7e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/35cab027331baf7e.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee7e63bc15b31913.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-83cebdb887f48834.js" defer=""></script><script src="/_next/static/chunks/pages/_app-3ca76a984b940bc2.js" defer=""></script><script src="/_next/static/chunks/465-4fe278bcc6195523.js" defer=""></script><script src="/_next/static/chunks/671-33206bff58acfdee.js" defer=""></script><script src="/_next/static/chunks/803-0cdd1b04f7cffd56.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bid%5D-46caa1db85c0b62b.js" defer=""></script><script src="/_next/static/DPwb1nK7hmgB_yIPdLqpw/_buildManifest.js" defer=""></script><script src="/_next/static/DPwb1nK7hmgB_yIPdLqpw/_ssgManifest.js" defer=""></script><style id="__jsx-1af872c17140788a">.img-text.jsx-1af872c17140788a{display:block;text-align:center;font-family:"Source Sans Pro",sans-serif;font-size:-webkit-calc(.8rem + .1vw);font-size:-moz-calc(.8rem + .1vw);font-size:calc(.8rem + .1vw);color:#1d2b35;word-wrap:"break-word";overflow-wrap:"break-word"}a.jsx-1af872c17140788a{margin:0;text-decoration:none;color:#1d2b35;border-bottom:1px solid}</style><style id="__jsx-4b699aa219fdc237">.blog-content.jsx-4b699aa219fdc237{display:-webkit-box;display:-webkit-flex;display:-moz-box;display:-ms-flexbox;display:flex;-webkit-box-flex:100%;-webkit-flex:100%;-moz-box-flex:100%;-ms-flex:100%;flex:100%;-webkit-box-orient:vertical;-webkit-box-direction:normal;-webkit-flex-direction:column;-moz-box-orient:vertical;-moz-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:1vw 25vw 1vw 25vw;width:50vw;max-width:50vw}</style></head><body><div id="__next"><header class="Header_header__iG0T4"><div class="flex items-center h-16 px-4"><h2><a class="font-bold text-2xl flex-1" href="/">PressBlog</a></h2><ul><li><a href="/about">About</a></li><li><a href="/blog/super-fast-python-numba#">GitHub Code</a></li></ul></div></header><main><div class="p-4 flex justify-center"><div class="w-11/12 md:w-7/12 prose prose-table"><article class="jsx-4b699aa219fdc237"><p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word"><picture class="jsx-1af872c17140788a"><img src="/images/super-fast-python-numba/super-fast-python-numba.jpg" alt="Super fast Python: Numba" style="width:100%;max-width:100%;height:auto;margin-left:0%" class="jsx-1af872c17140788a"/><span class="jsx-1af872c17140788a img-text"></span></picture></p>
<h1 style="font-family:&#x27;Ubuntu&#x27;, sans-serif;font-size:calc(1rem + 1.5vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">Super fast Python (Part-5): Numba</h1>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">This is the fifth and last post in the series on Python performance and Optimization. The series points out the utilization of inbuilt libraries, low-level code conversions, and other Python implementations to speed-up Python. The other posts included in this series are</p>
<ul style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013e6;margin:1vh 0 1vh calc(2vw);overflow-wrap:break-word">
<li>(Part-1): <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://santhalakshminarayana.github.io/blog/super-fast-python-why-python-slow">Why Python is slow?</a></li>
<li>(Part-2): <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://santhalakshminarayana.github.io/blog/super-fast-python-good-practices">Good practices to write fast Python code</a></li>
<li>(Part-3): <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://santhalakshminarayana.github.io/blog/super-fast-python-multi-processing">Multi-processing in Python</a></li>
<li>(Part-4): <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://santhalakshminarayana.github.io/blog/super-fast-python-cython">Use Cython to get speed as fast as C</a></li>
<li>(Part-5): Use Numba to speed up Python Functions (this post)</li>
</ul>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">In the last post about <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://santhalakshminarayana.github.io/blog/super-fast-python-cython">Cython to speed-up Python code</a>, we discussed writing Python code in C-style, compiling that code separately into an object file, and using that generated file as an import directly into Python. But, not all people would feel comfortable writing C-style code or even some might not know C at all. So, to deal with such cases and get the performant efficient code to speed-up Python, one can use <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.pydata.org/">Numba</a> instead. Numba translates Python code to machine code that executes almost as fast as C/C++ if optimized correctly.</p>
<h2 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 1vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">What is Numba?</h2>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Numba is a JIT (just-in-time) compiler that takes Python byte code and compiles it into machine code directly using <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://llvm.org/">LLVM</a> compiling mechanism. JIT is a type of interpreter that compiles frequently called code into machine code and caches that generated machine code to be used later for faster execution type. Here, Numba also takes Python code and generated machine code which the Python interpreter calls directly instead of interpreting and converting to machine code each time. Numba works best for numerical calculations, Array and Numpy operations, and loops. With Numba, we can write vectorized operations and parallelized loops to run on either CPU or GPU.</p>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Numba decorators are one of the many ways to invoke the JIT compilation. Numba provides different decorators to compile code in different modes and types, the common decorators used in Numba are:</p>
<ul style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013e6;margin:1vh 0 1vh calc(2vw);overflow-wrap:break-word">
<li>@jit - invoke JIT compilation for the provided function</li>
<li>@njit - @jit decorator with enabling strict no-python mode</li>
<li>@vectorize - convert normal functions into Numpy like <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">ufuncs</strong></li>
<li>@guvectorize - generalized <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">ufuncs</strong> for higher dimensional arrays</li>
<li>@stencil - make a function behave as a kernel for a <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">stencil</strong> like operation</li>
</ul>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Numba also provides different options to pass for some of these decorators to configure the JIT compilation behavior</p>
<ul style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013e6;margin:1vh 0 1vh calc(2vw);overflow-wrap:break-word">
<li>nopython</li>
<li>parallel</li>
<li>cache</li>
<li>nogil</li>
<li>fastmath</li>
<li>boundscheck</li>
<li>error_model</li>
<li>cuda</li>
</ul>
<h2 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 1vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">Numba @jit</h2>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word"><strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> decorator takes the Python function that needs to machine code compiled. When we make a call to the function we provided to <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong>, upon the first time calling, Numba compiles the function, caches the machine code, and this machine code is directly used for the execution. As compilation takes time, the first-time call to the function gives some latency. But, for consecutive function calls in the same runtime, just the cached machine code is used instead of re-compiling every time.</p>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Let&#x27;s consider the following simple function <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">solve_expression</em> as an example. <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">solve_expression</em> takes some arguments, checks some conditions, and calculates the final polynomial expression.</p>
<pre><code class="language-python">def solve_expression(x, a, b, c, d):
    A, B, C, D = a, b, c, d
    if a &gt; 10.1:
        A = 2 * a
    if 2.6 &lt;= b &lt; 8.3:
        B = b - 1/b
    if c &gt; 4.5:
        C = 4
    if d &lt; 9.0:
        D = d ** 2
    
    return A*(x**3) + B*(x**2) + C*(x) + D
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Now, use the <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> decorator to compile this function into machine code as</p>
<pre><code class="language-python">from numba import jit

@jit
def solve_expression(x, a, b, c, d):
    A, B, C, D = a, b, c, d
    if a &gt; 10.1:
        A = 2 * a
    if 2.6 &lt;= b &lt; 8.3:
        B = b - 1/b
    if c &gt; 4.5:
        C = 4
    if d &lt; 9.0:
        D = d ** 2
    
    return A*(x**3) + B*(x**2) + C*(x) + D
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">In the code snippet, we have imported the <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">jit</strong> function decorator and decorated <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">solve_expression</em> with it.</p>
<pre><code class="language-python">x, a, b, c, d = 2, 13, 1.2, 4, 7

res = solve_expression(x, a, b, c, d)
</code></pre>
<blockquote style="font-style:italic;background-color:#20a4f326;padding:10px;margin:1vh 0 1vh 0;border-left:5px solid #20a4f3e6">
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Inspect the Intermediate Representation (IR) of the function using solve_expression.inspect_types()</p>
</blockquote>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">As Numba <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> defers the JIT compilation until it encounters the first call to the function, the function call with arguments <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">solve_expression(x, a, b, c, d)</em> takes some time for executions. But, function calls later at this point will be fast.</p>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Now compare the speeds of the normal Python function and Numba JIT decorated function. Using <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">solve_expression.py_func()</em>, we can invoke the normal python function of this JIT decorated function.</p>
<pre><code class="language-python">%% timeit
res = solve_expression.py_func(x, a, b, c, d)

&#x27;&#x27;&#x27;Output
912 ns ± 3.47 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)
&#x27;&#x27;&#x27;
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">The normal Python function takes approx. 900 nanoseconds.</p>
<pre><code class="language-python">%%timeit
res = solve_expression(x, a, b, c, d)

&#x27;&#x27;&#x27;Output
277 ns ± 1.36 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)
&#x27;&#x27;&#x27;
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">And the Numba version takes approx. 280 nanoseconds. The Numba version is 3x times faster than the pure Python function.</p>
<h3 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 0.5vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">Compilation options</h3>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">For <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> decorator, we can pass multiple options to configure the compilation behavior</p>
<ul style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013e6;margin:1vh 0 1vh calc(2vw);overflow-wrap:break-word">
<li><strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">nopython</strong>: if True, enables no-python mode making code execution without Python interpreter interference</li>
<li><strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">nogil</strong>: if True, releases the GIL (only when <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">nopython=True</em>) inside the compiled function, useful for concurrent execution such as threads</li>
<li><strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">cache</strong>: if True, store the compiled code in local storage and use this code whenever the function is called instead of re-compiling for every runtime</li>
<li><strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">parallel</strong>: if True, enables automatic parallelization</li>
<li><strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">fastmath</strong>: if True, uses faster math operations but less safe floating-point operations</li>
</ul>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Apart from these, there are some more options available. You can check all options at <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/reference/jit-compilation.html#jit-functions">@jit reference</a>.</p>
<h2 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 1vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">Lazy and Eager compilation</h2>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Note that, as Python function arguments can take any time of arguments, Numba compiles the function for that specific type of the argument passed. If a new type of argument is passed to the function while calling, Numba re-compiles the code for that specific type.</p>
<h3 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 0.5vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">Lazy compilation</h3>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">The above <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">solve_expression()</em> function takes any type of argument. If we provide a function like this Numba calculates the optimization steps to be done based on the argument types provided at the first function call. In this way, Numba infers the argument types and compiles the specific version of the same function for different types.</p>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Ex: if we change the argument types like this</p>
<pre><code class="language-python"># previous values, x, a, b, c, d = 2, 13, 1.2, 4, 7
# new values
x, a, b, c, d = 3.9, 12, 5, 9.1, 14

res = solve_expression(x, a, b, c, d)
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">As the previous compiled function expects types for <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">x=int, a=int, b=float, c=int, d=int</em>, and in the latest function call we have changed some argument types. So, Numba re-compiles the function for new argument types. This mode of the compilation of code is called lazy compilation because Numba compiles for specific argument types only if it encounters them.</p>
<h3 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 0.5vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">Eager compilation</h3>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">For function overloading, we can specify function signatures with argument types and return types in a list with the least significant precision at the top. <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/reference/types.html">Numba types</a> follow Numpy convention types with different precision levels.</p>
<pre><code class="language-python">@jit([&#x27;int32(int32, int32)&#x27;,
      &#x27;i4(int32, int64)&#x27;, 
      &#x27;(f4, f8)&#x27;,
      &#x27;f8(f4, f4)&#x27;])
def func1(a, b):
    return a + b
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">In the above function, we passed function signatures as a list of strings. The syntax is return type is specified first and argument types are specified after. It is allowed to have no return type specified. Numba will infer the return type automatically and use that specification. Calling the function with argument types not provided in the list raises an error.</p>
<h2 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 1vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">@njit or @jit(nopython=True)</h2>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Numba <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> operates in two modes <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">nopython</em> and <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">object</em>. In <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">nopython</strong> mode, no interference of the Python interpreter is required and execution is very fast compared to normal mode. <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">object</strong> mode is the same as calling function without <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong>.</p>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Normally with the <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> decorator, Numba tries to compile in <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">nopython</strong> mode. If any part of the code cannot be compiled due to the presence of code that is not supported by Numba like a heterogenous dictionary, some string methods, etc, then Numba fallbacks to <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">object</strong> or normal Python mode for compilation. But still, it will improve the performance when loops are involved. If there is no code to optimize, <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> in object mode runs slower than the normal Python version as Numba compilation involves several function call overheads.</p>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">We can enable the strict <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">nopython</em> mode by passing the option to <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">@jit</strong> as <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">@jit(nopython=True)</em>. Numba also provides a separate decorator for this option. <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">@njit</em> decorator is an alias for <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">@jit(nopython=True)</em>.</p>
<pre><code class="language-python">@jit(nopython=True)
def f(a, b):
	return a + b

# or

@njit
def f(a, b):
	return a + b
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">With <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">nopython</strong> mode, if any code is present that requires object mode compilation, Numba will raise an error. The primary goal is to write functions that can be implemented in strict no-python mode.</p>
<hr style="margin:2vh 25% 2vh 25%;border:1px solid #07101380"/>
<h2 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 1vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">Numba and Numpy</h2>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Numba is best for Numpy arrays and supports some <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/reference/numpysupported.html">Numpy features</a> in no-python mode.</p>
<pre><code class="language-python">@njit([&#x27;int64[:](int64[:, :], int64[:, :])&#x27;])
def f(a, b):
    c = np.empty(a.shape[0], dtype=&#x27;int64&#x27;)
    
    for i in range(a.shape[0]):
        c[i] = a[i].sum() * b[i].sum()
    
    return c
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">The function takes 2 2D Numpy int64 arrays as arguments with the return type as an array of float64. The function calculates the sum of the product of the sum of each row of <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">a</em> and <em style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;background-color:#07101326;color:#071013f2;margin:0vh 0 1vh 0;padding:0 2px 0 2px;border-radius:2px">b</em>.</p>
<pre><code class="language-python">x, y, n = 1000, 1000, 1_000_000
l, h = 0, 100
a = np.random.randint(l, h, n).reshape(x, y)
b = np.random.randint(l, h, n).reshape(x, y)
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">If we compare both normal Numpy calculation of the above function and Numba compiled code,</p>
<pre><code class="language-python">%%timeit
# normal Python calculation
res = a.sum(axis=1) * b.sum(axis=1)

&#x27;&#x27;&#x27;Output:
1.4 ms ± 7.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
&#x27;&#x27;&#x27;
</code></pre>
<pre><code class="language-python">%%timeit 
# Numba compiled function
res = f(a, b)

&#x27;&#x27;&#x27;Output:
1.19 ms ± 15.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
&#x27;&#x27;&#x27;
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Numba compiled version takes <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">1.19 ms</strong> which is slightly faster than normal calculation with Numpy <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">1.4ms</strong>.</p>
<h2 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 1vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">@vectorize decorator</h2>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">One of the main reasons for Numpy speed is that most of the Numpy functions are <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numpy.org/doc/stable/user/basics.ufuncs.html">ufunc</a>s (universal functions) that are vectorized and implemented inside compiled layer of Numpy and hence the speed. We might run into a situation where we cannot find any existing Numpy functions for use and write a workaround by combining Numpy functions into a single operation. This new operation is not optimized and we might lose the speed that Numpy provides due to custom loops. To solve this problem, we can make any function as <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">ufunc</strong> that comes with vectorization and speed.</p>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">With <a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/user/vectorize.html">@vectorize</a>, Numba provides functionality to create custom vectorized universal functions. The universal function takes scalar values and returns a scalar value and these functions are applied over any Numpy arrays where array values are passed as single scalar values and an outside loop is automatically generated.</p>
<pre><code class="language-python">@vectorize([&#x27;float64(int64, int64)&#x27;])
def v_expr(a, b):
    return (a**2) + (a*3) + (b/2) + 10
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Here, we created a simple universal function that takes two scalar values and returns a calculated expression.</p>
<pre><code class="language-python">n = 1_000_000
l, h = 0, 100
a = np.random.randint(l, h, n)
b = np.random.randint(l, h, n)
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">The speed comparison of the Numpy expression and vectorized ufunc function gives</p>
<pre><code class="language-python">%%timeit
# general way of calculating Numpy expression
res = (a**2) + (a*3) + (b/2) + 10

&#x27;&#x27;&#x27;Output:
8.66 ms ± 71.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
&#x27;&#x27;&#x27;
</code></pre>
<pre><code class="language-python">%%timeit
# calculate expression with ufunc
res = v_expr(a, b)

&#x27;&#x27;&#x27;Output:
2.17 ms ± 96.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
&#x27;&#x27;&#x27;
</code></pre>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">the optimized function <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">v_expr</strong> takes <strong style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);font-style:normal;font-weight:bold;color:#1d2b35f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">2.17 ms</strong> which is 4x faster than the normal calculation with Numpy.</p>
<hr style="margin:2vh 25% 2vh 25%;border:1px solid #07101380"/>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">In this blog, we discussed basic Numba decorators and compared Numba compiled functions with normal Python functions. Explore other features of Numba like</p>
<ul style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013e6;margin:1vh 0 1vh calc(2vw);overflow-wrap:break-word">
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/user/parallel.html">automatic parallelization</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/user/parallel.html#explicit-parallel-loops">loop parallelization with prange</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/user/stencil.html">stencil kernel implementation for arrays</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://numba.readthedocs.io/en/stable/user/pycc.html">ahead-of-time compilation</a></li>
</ul>
<p style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013f2;margin:0vh 0 1vh 0;overflow-wrap:break-word">Remember that not every function can be passed to Numba as there are some limitations like</p>
<ul style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013e6;margin:1vh 0 1vh calc(2vw);overflow-wrap:break-word">
<li>Numba only supports a subset of Python code like classes, multi-dimensional dictionaries, etc, which are not supported yet.</li>
<li>As object mode compilation takes more time than the normal Python mode in some cases, it is better to check the speed of both normal and compiled code execution speed.</li>
<li>Support for external libraries like Pandas is not supported.</li>
<li>As Numba re-implements some Numpy APIs, there may be different behavior expected.</li>
</ul>
<hr style="margin:2vh 25% 2vh 25%;border:1px solid #07101380"/>
<h3 style="font-family:&#x27;Maven Pro&#x27;, sans-serif;font-size:calc(1rem + 0.5vw);color:#1d2b35;margin:1vh 0 1vh 0;overflow-wrap:break-word" id="">References</h3>
<ul style="font-family:&#x27;Source Sans Pro&#x27;, sans-serif;font-size:calc(1rem + 0.1vw);color:#071013e6;margin:1vh 0 1vh calc(2vw);overflow-wrap:break-word">
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://github.com/ContinuumIO/gtc2020-numba">https://github.com/ContinuumIO/gtc2020-numba</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://www.nvidia.com/en-us/glossary/data-science/numba/">https://www.nvidia.com/en-us/glossary/data-science/numba/</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://www.chrisvoncsefalvay.com/2019/03/23/jit-fast/">https://www.chrisvoncsefalvay.com/2019/03/23/jit-fast/</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://towardsdatascience.com/numba-weapon-of-mass-optimization-43cdeb76c7da">https://towardsdatascience.com/numba-weapon-of-mass-optimization-43cdeb76c7da</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://www.infoworld.com/article/3622013/speed-up-your-python-with-numba.html">https://www.infoworld.com/article/3622013/speed-up-your-python-with-numba.html</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://coderzcolumn.com/tutorials/python/numba">https://coderzcolumn.com/tutorials/python/numba</a></li>
<li><a style="color:#071013;text-decoration:none;cursor:pointer;border-bottom:1px dashed #fb232e;font-size:calc(1rem + 0.1vw);font-weight:bold;overflow-wrap:break-word" target="_blank" rel="noreferrer" href="https://towardsdatascience.com/numpy-ufuncs-the-magic-behind-vectorized-functions-8cc3ba56aa2c">https://towardsdatascience.com/numpy-ufuncs-the-magic-behind-vectorized-functions-8cc3ba56aa2c</a></li>
</ul></article></div></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postMetadata":{"title":"Super fast Python (Part-5): Numba","description":"Speed up Numerical computations and functions in Python with Numba and Numpy.","imgName":"super-fast-python-numba/super-fast-python-numba.jpg","date":"January, 6th. 2023","tags":["python-performance"],"keywords":["numba","python-performance'","python-optimize","python","fast-python","speed","jit","numba-numpy"],"id":"super-fast-python-numba"},"postContent":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    h1: \"h1\",\n    ul: \"ul\",\n    li: \"li\",\n    a: \"a\",\n    h2: \"h2\",\n    strong: \"strong\",\n    em: \"em\",\n    pre: \"pre\",\n    code: \"code\",\n    blockquote: \"blockquote\",\n    h3: \"h3\",\n    hr: \"hr\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"super-fast-python-numba/super-fast-python-numba.jpg\",\n        alt: \"Super fast Python: Numba\"\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Super fast Python (Part-5): Numba\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This is the fifth and last post in the series on Python performance and Optimization. The series points out the utilization of inbuilt libraries, low-level code conversions, and other Python implementations to speed-up Python. The other posts included in this series are\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"(Part-1): \", _jsx(_components.a, {\n          href: \"https://santhalakshminarayana.github.io/blog/super-fast-python-why-python-slow\",\n          children: \"Why Python is slow?\"\n        })]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"(Part-2): \", _jsx(_components.a, {\n          href: \"https://santhalakshminarayana.github.io/blog/super-fast-python-good-practices\",\n          children: \"Good practices to write fast Python code\"\n        })]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"(Part-3): \", _jsx(_components.a, {\n          href: \"https://santhalakshminarayana.github.io/blog/super-fast-python-multi-processing\",\n          children: \"Multi-processing in Python\"\n        })]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"(Part-4): \", _jsx(_components.a, {\n          href: \"https://santhalakshminarayana.github.io/blog/super-fast-python-cython\",\n          children: \"Use Cython to get speed as fast as C\"\n        })]\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"(Part-5): Use Numba to speed up Python Functions (this post)\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In the last post about \", _jsx(_components.a, {\n        href: \"https://santhalakshminarayana.github.io/blog/super-fast-python-cython\",\n        children: \"Cython to speed-up Python code\"\n      }), \", we discussed writing Python code in C-style, compiling that code separately into an object file, and using that generated file as an import directly into Python. But, not all people would feel comfortable writing C-style code or even some might not know C at all. So, to deal with such cases and get the performant efficient code to speed-up Python, one can use \", _jsx(_components.a, {\n        href: \"https://numba.pydata.org/\",\n        children: \"Numba\"\n      }), \" instead. Numba translates Python code to machine code that executes almost as fast as C/C++ if optimized correctly.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"What is Numba?\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Numba is a JIT (just-in-time) compiler that takes Python byte code and compiles it into machine code directly using \", _jsx(_components.a, {\n        href: \"https://llvm.org/\",\n        children: \"LLVM\"\n      }), \" compiling mechanism. JIT is a type of interpreter that compiles frequently called code into machine code and caches that generated machine code to be used later for faster execution type. Here, Numba also takes Python code and generated machine code which the Python interpreter calls directly instead of interpreting and converting to machine code each time. Numba works best for numerical calculations, Array and Numpy operations, and loops. With Numba, we can write vectorized operations and parallelized loops to run on either CPU or GPU.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Numba decorators are one of the many ways to invoke the JIT compilation. Numba provides different decorators to compile code in different modes and types, the common decorators used in Numba are:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"@jit - invoke JIT compilation for the provided function\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"@njit - @jit decorator with enabling strict no-python mode\"\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"@vectorize - convert normal functions into Numpy like \", _jsx(_components.strong, {\n          children: \"ufuncs\"\n        })]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"@guvectorize - generalized \", _jsx(_components.strong, {\n          children: \"ufuncs\"\n        }), \" for higher dimensional arrays\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"@stencil - make a function behave as a kernel for a \", _jsx(_components.strong, {\n          children: \"stencil\"\n        }), \" like operation\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Numba also provides different options to pass for some of these decorators to configure the JIT compilation behavior\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"nopython\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"parallel\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"cache\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"nogil\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"fastmath\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"boundscheck\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"error_model\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"cuda\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Numba @jit\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" decorator takes the Python function that needs to machine code compiled. When we make a call to the function we provided to \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \", upon the first time calling, Numba compiles the function, caches the machine code, and this machine code is directly used for the execution. As compilation takes time, the first-time call to the function gives some latency. But, for consecutive function calls in the same runtime, just the cached machine code is used instead of re-compiling every time.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Let's consider the following simple function \", _jsx(_components.em, {\n        children: \"solve_expression\"\n      }), \" as an example. \", _jsx(_components.em, {\n        children: \"solve_expression\"\n      }), \" takes some arguments, checks some conditions, and calculates the final polynomial expression.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"def solve_expression(x, a, b, c, d):\\n    A, B, C, D = a, b, c, d\\n    if a \u003e 10.1:\\n        A = 2 * a\\n    if 2.6 \u003c= b \u003c 8.3:\\n        B = b - 1/b\\n    if c \u003e 4.5:\\n        C = 4\\n    if d \u003c 9.0:\\n        D = d ** 2\\n    \\n    return A*(x**3) + B*(x**2) + C*(x) + D\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now, use the \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" decorator to compile this function into machine code as\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"from numba import jit\\n\\n@jit\\ndef solve_expression(x, a, b, c, d):\\n    A, B, C, D = a, b, c, d\\n    if a \u003e 10.1:\\n        A = 2 * a\\n    if 2.6 \u003c= b \u003c 8.3:\\n        B = b - 1/b\\n    if c \u003e 4.5:\\n        C = 4\\n    if d \u003c 9.0:\\n        D = d ** 2\\n    \\n    return A*(x**3) + B*(x**2) + C*(x) + D\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In the code snippet, we have imported the \", _jsx(_components.strong, {\n        children: \"jit\"\n      }), \" function decorator and decorated \", _jsx(_components.em, {\n        children: \"solve_expression\"\n      }), \" with it.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"x, a, b, c, d = 2, 13, 1.2, 4, 7\\n\\nres = solve_expression(x, a, b, c, d)\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.blockquote, {\n      children: [\"\\n\", _jsx(_components.p, {\n        children: \"Inspect the Intermediate Representation (IR) of the function using solve_expression.inspect_types()\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"As Numba \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" defers the JIT compilation until it encounters the first call to the function, the function call with arguments \", _jsx(_components.em, {\n        children: \"solve_expression(x, a, b, c, d)\"\n      }), \" takes some time for executions. But, function calls later at this point will be fast.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Now compare the speeds of the normal Python function and Numba JIT decorated function. Using \", _jsx(_components.em, {\n        children: \"solve_expression.py_func()\"\n      }), \", we can invoke the normal python function of this JIT decorated function.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"%% timeit\\nres = solve_expression.py_func(x, a, b, c, d)\\n\\n'''Output\\n912 ns ± 3.47 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\\n'''\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The normal Python function takes approx. 900 nanoseconds.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"%%timeit\\nres = solve_expression(x, a, b, c, d)\\n\\n'''Output\\n277 ns ± 1.36 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\\n'''\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"And the Numba version takes approx. 280 nanoseconds. The Numba version is 3x times faster than the pure Python function.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Compilation options\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" decorator, we can pass multiple options to configure the compilation behavior\"]\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"nopython\"\n        }), \": if True, enables no-python mode making code execution without Python interpreter interference\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"nogil\"\n        }), \": if True, releases the GIL (only when \", _jsx(_components.em, {\n          children: \"nopython=True\"\n        }), \") inside the compiled function, useful for concurrent execution such as threads\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"cache\"\n        }), \": if True, store the compiled code in local storage and use this code whenever the function is called instead of re-compiling for every runtime\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"parallel\"\n        }), \": if True, enables automatic parallelization\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [_jsx(_components.strong, {\n          children: \"fastmath\"\n        }), \": if True, uses faster math operations but less safe floating-point operations\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Apart from these, there are some more options available. You can check all options at \", _jsx(_components.a, {\n        href: \"https://numba.readthedocs.io/en/stable/reference/jit-compilation.html#jit-functions\",\n        children: \"@jit reference\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Lazy and Eager compilation\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Note that, as Python function arguments can take any time of arguments, Numba compiles the function for that specific type of the argument passed. If a new type of argument is passed to the function while calling, Numba re-compiles the code for that specific type.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Lazy compilation\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The above \", _jsx(_components.em, {\n        children: \"solve_expression()\"\n      }), \" function takes any type of argument. If we provide a function like this Numba calculates the optimization steps to be done based on the argument types provided at the first function call. In this way, Numba infers the argument types and compiles the specific version of the same function for different types.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Ex: if we change the argument types like this\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"# previous values, x, a, b, c, d = 2, 13, 1.2, 4, 7\\n# new values\\nx, a, b, c, d = 3.9, 12, 5, 9.1, 14\\n\\nres = solve_expression(x, a, b, c, d)\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"As the previous compiled function expects types for \", _jsx(_components.em, {\n        children: \"x=int, a=int, b=float, c=int, d=int\"\n      }), \", and in the latest function call we have changed some argument types. So, Numba re-compiles the function for new argument types. This mode of the compilation of code is called lazy compilation because Numba compiles for specific argument types only if it encounters them.\"]\n    }), \"\\n\", _jsx(_components.h3, {\n      children: \"Eager compilation\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"For function overloading, we can specify function signatures with argument types and return types in a list with the least significant precision at the top. \", _jsx(_components.a, {\n        href: \"https://numba.readthedocs.io/en/stable/reference/types.html\",\n        children: \"Numba types\"\n      }), \" follow Numpy convention types with different precision levels.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"@jit(['int32(int32, int32)',\\n      'i4(int32, int64)', \\n      '(f4, f8)',\\n      'f8(f4, f4)'])\\ndef func1(a, b):\\n    return a + b\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"In the above function, we passed function signatures as a list of strings. The syntax is return type is specified first and argument types are specified after. It is allowed to have no return type specified. Numba will infer the return type automatically and use that specification. Calling the function with argument types not provided in the list raises an error.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"@njit or @jit(nopython=True)\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Numba \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" operates in two modes \", _jsx(_components.em, {\n        children: \"nopython\"\n      }), \" and \", _jsx(_components.em, {\n        children: \"object\"\n      }), \". In \", _jsx(_components.strong, {\n        children: \"nopython\"\n      }), \" mode, no interference of the Python interpreter is required and execution is very fast compared to normal mode. \", _jsx(_components.strong, {\n        children: \"object\"\n      }), \" mode is the same as calling function without \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \".\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Normally with the \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" decorator, Numba tries to compile in \", _jsx(_components.strong, {\n        children: \"nopython\"\n      }), \" mode. If any part of the code cannot be compiled due to the presence of code that is not supported by Numba like a heterogenous dictionary, some string methods, etc, then Numba fallbacks to \", _jsx(_components.strong, {\n        children: \"object\"\n      }), \" or normal Python mode for compilation. But still, it will improve the performance when loops are involved. If there is no code to optimize, \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" in object mode runs slower than the normal Python version as Numba compilation involves several function call overheads.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"We can enable the strict \", _jsx(_components.em, {\n        children: \"nopython\"\n      }), \" mode by passing the option to \", _jsx(_components.strong, {\n        children: \"@jit\"\n      }), \" as \", _jsx(_components.em, {\n        children: \"@jit(nopython=True)\"\n      }), \". Numba also provides a separate decorator for this option. \", _jsx(_components.em, {\n        children: \"@njit\"\n      }), \" decorator is an alias for \", _jsx(_components.em, {\n        children: \"@jit(nopython=True)\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"@jit(nopython=True)\\ndef f(a, b):\\n\\treturn a + b\\n\\n# or\\n\\n@njit\\ndef f(a, b):\\n\\treturn a + b\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"With \", _jsx(_components.strong, {\n        children: \"nopython\"\n      }), \" mode, if any code is present that requires object mode compilation, Numba will raise an error. The primary goal is to write functions that can be implemented in strict no-python mode.\"]\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsx(_components.h2, {\n      children: \"Numba and Numpy\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Numba is best for Numpy arrays and supports some \", _jsx(_components.a, {\n        href: \"https://numba.readthedocs.io/en/stable/reference/numpysupported.html\",\n        children: \"Numpy features\"\n      }), \" in no-python mode.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"@njit(['int64[:](int64[:, :], int64[:, :])'])\\ndef f(a, b):\\n    c = np.empty(a.shape[0], dtype='int64')\\n    \\n    for i in range(a.shape[0]):\\n        c[i] = a[i].sum() * b[i].sum()\\n    \\n    return c\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The function takes 2 2D Numpy int64 arrays as arguments with the return type as an array of float64. The function calculates the sum of the product of the sum of each row of \", _jsx(_components.em, {\n        children: \"a\"\n      }), \" and \", _jsx(_components.em, {\n        children: \"b\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"x, y, n = 1000, 1000, 1_000_000\\nl, h = 0, 100\\na = np.random.randint(l, h, n).reshape(x, y)\\nb = np.random.randint(l, h, n).reshape(x, y)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If we compare both normal Numpy calculation of the above function and Numba compiled code,\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"%%timeit\\n# normal Python calculation\\nres = a.sum(axis=1) * b.sum(axis=1)\\n\\n'''Output:\\n1.4 ms ± 7.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\\n'''\\n\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"%%timeit \\n# Numba compiled function\\nres = f(a, b)\\n\\n'''Output:\\n1.19 ms ± 15.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\\n'''\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Numba compiled version takes \", _jsx(_components.strong, {\n        children: \"1.19 ms\"\n      }), \" which is slightly faster than normal calculation with Numpy \", _jsx(_components.strong, {\n        children: \"1.4ms\"\n      }), \".\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"@vectorize decorator\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"One of the main reasons for Numpy speed is that most of the Numpy functions are \", _jsx(_components.a, {\n        href: \"https://numpy.org/doc/stable/user/basics.ufuncs.html\",\n        children: \"ufunc\"\n      }), \"s (universal functions) that are vectorized and implemented inside compiled layer of Numpy and hence the speed. We might run into a situation where we cannot find any existing Numpy functions for use and write a workaround by combining Numpy functions into a single operation. This new operation is not optimized and we might lose the speed that Numpy provides due to custom loops. To solve this problem, we can make any function as \", _jsx(_components.strong, {\n        children: \"ufunc\"\n      }), \" that comes with vectorization and speed.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"With \", _jsx(_components.a, {\n        href: \"https://numba.readthedocs.io/en/stable/user/vectorize.html\",\n        children: \"@vectorize\"\n      }), \", Numba provides functionality to create custom vectorized universal functions. The universal function takes scalar values and returns a scalar value and these functions are applied over any Numpy arrays where array values are passed as single scalar values and an outside loop is automatically generated.\"]\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"@vectorize(['float64(int64, int64)'])\\ndef v_expr(a, b):\\n    return (a**2) + (a*3) + (b/2) + 10\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Here, we created a simple universal function that takes two scalar values and returns a calculated expression.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"n = 1_000_000\\nl, h = 0, 100\\na = np.random.randint(l, h, n)\\nb = np.random.randint(l, h, n)\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The speed comparison of the Numpy expression and vectorized ufunc function gives\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"%%timeit\\n# general way of calculating Numpy expression\\nres = (a**2) + (a*3) + (b/2) + 10\\n\\n'''Output:\\n8.66 ms ± 71.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\\n'''\\n\"\n      })\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"language-python\",\n        children: \"%%timeit\\n# calculate expression with ufunc\\nres = v_expr(a, b)\\n\\n'''Output:\\n2.17 ms ± 96.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\\n'''\\n\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"the optimized function \", _jsx(_components.strong, {\n        children: \"v_expr\"\n      }), \" takes \", _jsx(_components.strong, {\n        children: \"2.17 ms\"\n      }), \" which is 4x faster than the normal calculation with Numpy.\"]\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsx(_components.p, {\n      children: \"In this blog, we discussed basic Numba decorators and compared Numba compiled functions with normal Python functions. Explore other features of Numba like\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://numba.readthedocs.io/en/stable/user/parallel.html\",\n          children: \"automatic parallelization\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://numba.readthedocs.io/en/stable/user/parallel.html#explicit-parallel-loops\",\n          children: \"loop parallelization with prange\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://numba.readthedocs.io/en/stable/user/stencil.html\",\n          children: \"stencil kernel implementation for arrays\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://numba.readthedocs.io/en/stable/user/pycc.html\",\n          children: \"ahead-of-time compilation\"\n        })\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Remember that not every function can be passed to Numba as there are some limitations like\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Numba only supports a subset of Python code like classes, multi-dimensional dictionaries, etc, which are not supported yet.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"As object mode compilation takes more time than the normal Python mode in some cases, it is better to check the speed of both normal and compiled code execution speed.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"Support for external libraries like Pandas is not supported.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"As Numba re-implements some Numpy APIs, there may be different behavior expected.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsx(_components.h3, {\n      children: \"References\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://github.com/ContinuumIO/gtc2020-numba\",\n          children: \"https://github.com/ContinuumIO/gtc2020-numba\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://www.nvidia.com/en-us/glossary/data-science/numba/\",\n          children: \"https://www.nvidia.com/en-us/glossary/data-science/numba/\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://www.chrisvoncsefalvay.com/2019/03/23/jit-fast/\",\n          children: \"https://www.chrisvoncsefalvay.com/2019/03/23/jit-fast/\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://towardsdatascience.com/numba-weapon-of-mass-optimization-43cdeb76c7da\",\n          children: \"https://towardsdatascience.com/numba-weapon-of-mass-optimization-43cdeb76c7da\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://www.infoworld.com/article/3622013/speed-up-your-python-with-numba.html\",\n          children: \"https://www.infoworld.com/article/3622013/speed-up-your-python-with-numba.html\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://coderzcolumn.com/tutorials/python/numba\",\n          children: \"https://coderzcolumn.com/tutorials/python/numba\"\n        })\n      }), \"\\n\", _jsx(_components.li, {\n        children: _jsx(_components.a, {\n          href: \"https://towardsdatascience.com/numpy-ufuncs-the-magic-behind-vectorized-functions-8cc3ba56aa2c\",\n          children: \"https://towardsdatascience.com/numpy-ufuncs-the-magic-behind-vectorized-functions-8cc3ba56aa2c\"\n        })\n      }), \"\\n\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}},"id":"super-fast-python-numba"},"__N_SSG":true},"page":"/blog/[id]","query":{"id":"super-fast-python-numba"},"buildId":"DPwb1nK7hmgB_yIPdLqpw","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>