---
title: Linkedin Learning
date: '2021-08-15'
tags: ['school', 'linkedin']
---

# SQL #

SQL (Structured Query Language) was designed to operate and manage relational databases that store data inside tables consisting of rows (records) and columns (fields). Each row must have a unique key (id), the column that stores the unique keys is called the primary key. To create relations between tables we can associate the primary key of one table into another as a foreign key. There are many SQL Database Management Systems (DBMS) with different SQL syntax, examples of RDBMS include [Oracle](https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/index.html), [MySQL](https://dev.mysql.com/doc/), [MS SQL](https://docs.microsoft.com/en-us/sql/?view=sql-server-ver16), [PostgreSQL](https://www.postgresql.org/docs/), [IBMDb2](https://www.ibm.com/support/pages/db2-database-product-documentation#ic), [Access](https://docs.microsoft.com/en-us/office/client-developer/access/desktop-database-reference/microsoft-access-sql-reference) and [SQLite](https://www.sqlite.org/docs.html). Every DBMS is able to create database applications that can create, read, update and delete data (CRUD).

Statements or data manipulation language statements (DML) are the unit of execution in SQL and may include Clauses to filter the data. We can group statements into transactions, transactions are a collection of DML statements that form a united logical block, this means that if one statement fails then the entire transaction will and the database reverts to its last stable state. Transaction control language statements (TCL) such as `BEGIN TRANSACTION`, `END TRANSACTION`, `ROLLBACK` and `SAVEPOINT` improve data integrity and performance. In some systems `END TRANSACTION` is replaced by `COMMIT`. Rollback will discard all pending data changes and end the transaction reverting to the last save point, commit will end the current transaction and save all the data changes while savepoint creates a marker within the transaction as a reference to any rollback.

Data definition language statements (DDL) such as `CREATE` are used to manipulate the database itself with the use of constraints. Constraints are rules at a table or column level that limit the available statements that can be executed, if a statement violates a constraint or tries to reference a non-existence value then an Integrity Constraint Error will be raised.

**Statements**

* `SELECT`: Most complex SQL statement, used for every query that returns values.

```sql
-- Return a string and apply an identifier to its column
SELECT 'Hello World!' AS Column_Alias;
-- Return every row and column from a table
SELECT * FROM Table_Name;
-- Filter results to only show distinct values in Column1
SELECT DISTINCT Column1 FROM Table_Name;
-- Return every row of 2 columns, filter data to rows where Column1 has a value of 1
-- Filter data where Column2 is NULL and where Column3 is not NULL
-- Order the results in descending ASCII order and limit to 5 rows starting at the 10th one.
SELECT Column1, Column2, Column3, Column4 FROM Table_Name 
	WHERE Column1 = 1 AND Column2 IS NULL AND Column3 IS NOT NULL
	ORDER BY Column4 DESC
	LIMIT 5 OFFSET 10;
-- Count how many rows have a particular set of values for Column1 and Column2
SELECT COUNT(*) FROM Table_Name WHERE Column1 > 3 AND Column2 != 'Value';
-- You can aggragate data into groups and count instances for each one
SELECT Column1, COUNT(Column2) FROM Table_Name GROUP BY Column1;
-- Filter where where the value of Column1 starts with any letter followed by (tem)
SELECT * FROM Table_Name WHERE Column1 LIKE '_tem%' ORDER BY Column1;
-- Filter rows if the value of Column2 is equal to 1 or 2
-- The IN keyword is tipically used with subselects since they produce a list of values
SELECT * FROM Table_Name WHERE Column2 IN (1, 2) ORDER BY Column1 ASC;
-- Filter using conditional expressions, here WHERE is equivalent to IF.
SELECT 
	CASE WHEN Column1=1 THEN 'true' ELSE 'false' END AS Result1,
	CASE WHEN Column2='a' THEN 1 ELSE 2 END AS Result2
	FROM Table_Name;
-- Filter by showing the data from two tables if their Column1 (ID) values match
SELECT l.Column2 AS Left_Column, r.Column2 AS Right_Column
	FROM Table_Name AS l JOIN Table2_Name AS r ON l.Column1 = r.Column1;
-- Filter by showing the data from three tables based on their Column2 (ID) values
-- Also include every single row (all - LEFT) from the Second Table
SELECT ft.Column1 AS Left_Column, st.Column1 AS All_Column, tt.Column1 AS Right_Column
	FROM First_Table AS ft
	LEFT JOIN Second_Table AS st ON ft.Column2 = st.Column2
	JOIN Third_Table AS tt ON ft.Column2 = tt.Column2;
	WHERE ft.Column3 = 1 OR tt.Column3 = 2
-- To filter Aggregate Data selections we need to use HAVING instead of WHERE
SELECT st.Column2 AS Name_Result, COUNT(ft.Column4) AS Group_Count
	FROM First_Table AS ft 
	JOIN Second_Table AS st ON ft.Column1 = st.Column1
	WHERE st.Column3 = 1
	GROUP BY ft.Column4
	HAVING Group_Count >= 10
	ORDER BY Group_Count ASC, Name_Result;
-- Reference the Data Dictionary Table or Schema sqlite_schema
-- Names every table in the database excluding those managed by SQLite
SELECT name FROM sqlite_schema WHERE type='table' AND name NOT LIKE 'sqlite_%';
```

* `CREATE`: Create a new element, usually a table inside the database.

```sql
-- Create a new table
CREATE TABLE Table_Name (Column1 TEXT, Column2 INTEGER)
-- Add constraints when creating a table
CREATE TABLE Table_Name (
	id INTEGER PRIMARY KEY,
	Column1 TEXT NOT NULL,
	Column2 INTEGER DEFAULT 100,
	Column3 INTEGER UNIQUE,
)
-- Add a foreign key to link the new table to the previous one
CREATE TABLE Table2_Name (
	id INTEGER PRIMARY KEY,
	id_OtherTable INTEGER,
	FOREIGN KEY (id_OtherTable) REFERENCES Table_Name(id)
)
-- Create a View using a Subselect, views can be used as tables.
-- By replacing VIEW with TABLE this is another way of creating tables.
CREATE VIEW View_Name AS
	SELECT * FROM Table_Name;
-- Trigger an update if a row is inserted into one table.
-- You can reference the newly inseted row with the Keyworkd NEW.
CREATE TRIGGER Trigger_Name AFTER INSERT ON Table_Name
	BEGIN
		UPDATE Table2_Name SET Column1 = NEW.Column1
			WHERE Table2_Name.Column2 = NEW.Column2
	END;
-- Trigger to prevent a transaction based on the updated  value of a column
CREATE TRIGGER Trigger_Name BEFORE UPDATE ON Table_Name
	BEGIN
		SELECT RAISE(ROLLBACK, 'Can''t update if value Column2 is 1') 
			FROM Table_Name WHERE Column1 = NEW.Column1 AND Column2 = 1;
	END;
-- Trigger to create multiple timestams and insert a row into a transaction log
CREATE TRIGGER Trigger_Name AFTER INSERT ON Table_Name
	BEGIN
		UPDATE Table_Name SET Stamp = DATETIME('now') WHERE Column1 = NEW.Column1;
		UPDATE Table2_Name SET Updated = NEW.Column2, 
			Stamp = DATETIME('now') WHERE Table2_Name.Updated = NEW.Column3;
		INSERT INTO Table3_Name (stamp, event_name, table_name, table_id)
			VALUES (DATETIME('now'), 'INSERT', 'Table_Name', NEW.Column1)
	END;
```

* `INSERT`: Used for adding rows to a table, unpopulated fields will default to NULL.

```sql
-- Insert a new row with the table's default values (By default NULL)
INSERT INTO Table_Name DEFAULT VALUES;
-- Insert a new row with values for each column
INSERT INTO Table_Name (Column1, Column2, Column3) VALUES ('String', 1, 2)
-- Copy the rows from one table into another
INSERT INTO Table_Name (Column1, Column2) 
	SELECT Column1, Column2 FROM Table2_Name WHERE Column2 = 1;
```

* `DROP`: Used to remove a table, index, view or trigger from the database.

```sql
-- Delete a table, trigger and a view. Check first if they exist.
DROP TABLE IF EXISTS Table_Name;
DROP TRIGGER IF EXISTS Trigger_Name;
DROP VIEW IF EXISTS View_Name;
```

* `ALTER`: Used to alter an existing table to rename it, add columns, rename columns or drop columns.

```sql
-- Add a new field to an existing table with a default value 
ALTER TABLE Table_Name ADD Column_Name TEXT DEFAULT 'DefaultValue';
-- Rename an existing table
ALTER TABLE Table_Name RENAME TO New_Table_Name;
```

* `UPDATE`: Used for updating the value of the rows from a table.

```sql
-- Set the value of column(s) for every row where the value of a column is equal to 1
UPDATE Table_Name SET Column1 = 'UpdatedValue' WHERE Column2 = 1
```

* `DELETE`: Used for deleting rows from a table.

```sql
-- Delete every row from the table where the value of a column is equal to 1
DELETE FROM Table_Name WHERE Column1 = 1
```



**Functions**

```sql
-- https://www.sqlite.org/lang_corefunc.html
-- Return the Data Type of a value
SELECT TYPEOF('HW');
-- Return the length of a string
SELECT LENGTH('Hello World');
-- Return substring World - (String, start, length)
SELECT SUBSTR('Hello World', 7, 5);
-- Remove whitespaces from a string or a delimiter
-- Note that TRIM doesn't work on the middle dash in (-H-W-)
SELECT TRIM(' HW ');
SELECT LTRIM(' HW');
SELECT RTRIM('HW ');
SELECT TRIM('-H-W-', '-');
-- Lower or Upper Case functions
SELECT LOWER('HW');
SELECT UPPER('hw');
-- Try to convert an Integer to Floating Point number
SELECT CAST(1 AS REAL);
-- Round a floating number to 3 decimal places
SELECT ROUND(2.55555, 3)
-- Standard SQL Date is (YYYY-MM-DD HH:MM:SS)
-- Return Current UTC Time and with time calculations
SELECT DATETIME('now', '+3 hours', '+27 minutes', '-1 day', '+3 years')
-- Return the Average, Minimum and Sum of an entire Column or by Groups (Aggregate)
SELECT AVG(Column1) FROM First_Table;
SELECT MIN(Column1) FROM First_Table;
SELECT Column2, SUM(Column1) FROM First_Table GROUP BY Column2;
```

**Resources**

* SQLite Online: https://sqliteonline.com/
* SQLite Studio: https://sqlitestudio.pl/
* SQLite Docs: https://www.sqlite.org/index.html
* SQLite Example Database: https://github.com/scottsimpson/restaurant-database
* SQLite Example Database: https://github.com/rizkyashari/sql-essential-training
* SQLite Code Challenges: https://github.com/ghoshtrina/SQL-Code-Challenges
* Oracle SQL Online: https://livesql.oracle.com

***

# NoSQL #

**MongoDB**

NoSQL stands for Not Only SQL, it's a modern take on SQL designed for speed, flexibility and scalability while being associated with agile development, web apps and big data. NoSQL trades strict schemas for fluid descriptions, for example each row can have it's own set of fields based on how it was populated. Even if NoSQL databases are useful, relational databases continue to excel at banking, accounting and internal systems that won't scale.

* Relational Databases: 
	* Data Consistency Model: ACID (Atomic, Consistent, Isolated, Durable)
	* Pros include: Precise data, team fluency, transactional integrity, high consistency (pessimistic), complex query development and structured data.
	* Cons include: Slower schema development, lower performance on big data and expensive scaling.

* NoSQL Databases:
	* Data Consistency Model: BASIC (Basically Available, Soft state, Eventually consistent). 
	* Pros include: No schema definition, big data capabilities, availability and fault tolerance.
	* Cons include: Approximate data, team training, lack of transactional integrity, weak consistency over time (optimistic), expensive development of complex queries and unstructured data.


The four main categories of NoSQL database management systems are:

1. Key-Value (Redis, DynamoDB, Oracle NoSQL): Used for simple dictionary-like storage, fast and simple queries on basic information, it's highly scalable.
	1. Applications: Cashing web app data, leaderboards with realtime slicing, restoring user sessions, realtime inventory, fraud detection and client claim processing.
2. Document (MongoDB, Apache CouchDB, Azure CosmosDB): Used as a general purpose key-value system with values as individual documents. 
	1. Applications: Content management systems (CMSs), general websites, large document oriented apps, websites that display unstructured data, user profiles, real time analytics and big data operations.
3. Wide-Column (Cassandra and HBase): Used for large volumes of data and designed around fast predefined queries like searching. They are considered a subset of key-value databases that mix in tables with rows and columns from RDBMS, however this tables can be modified at runtime.
	1. Applications: Inventory management, realtime analytics, big data operations.
4. Graph (Neo4j, JanusGraph): Used for relational patterns between multidimensional data sets. Everything is stored as nodes with certain relationships, great for deeply interconnected databases.
	1. Applications: Neural networks, social networks, fraud detection and recommendations.

In database management the CAP Theorem (Consistency, Availability and Partition Tolerance) stablishes that you can have at most two out of the three qualities of a DBMS. Consistency refers to high data integrity and accuracy. Availability refers to the ability to write and read regardless of system failures. Partition Tolerance refers to how many faults can the system withstand before eventually crashing. Based on this theorem we can classify most DBMS into three categories:

1. Consistent and Available (CA): Lacks Partition Tolerance: Neo4j
2. Consistent and Partition Tolerant (CP): Lacks Availability: MongoDB, HBase, Redis.
3. Available and Partition Tolerant (AP): Lacks Consistency: CouchDB, Cassandra, DynamoDB.

***

# Terraform #

Terraform is considered Infrastructure as Code (IaC) and it's used to simplify the creation and management of Backend by automating its deployment. Other IaC include ARM Template and BICEP, the latter being native to Azure (automatic state file) while Terraform is cloud agnostic (manual state file). Terraform is developed by HashCorp and it uses declarative configuration files made up of blocks, arguments and exceptions to deploy standard resource components, typically through cloud API's.

**Commands**

```bash
# Help with Terraform commands.
terraform -help
# Init Env, prepare working directory for additional commands.
terraform init 
# Check if the configuration is valid.
terraform validate
# Show staged changes from the current configuration.
terraform plan
# Output plan to a file
terraform plan -out myplan.tfplan
# Apply staged changes 
terraform apply
# Skip confirmation
terraform apply -auto-approve
# Run plan or apply with a separate secrets file
terraform plan -var-file="secrets.tfvars"
terraform apply -var-file="secrets.tfvars"
# Destroy all terraform infrastructure on the working directory
terraform destroy -var-file="secrets.tfvars"
```

You can have multiple state files (state data) within a single directory (CLI Workspaces) or multiple working directories (Cloud Workspaces) for any given project.

```bash
# Show current CLI workspace being edited
terraform workspace show
# Show every CLI workspaces in current directory
terraform workspace list
# Create a new CLI workspace
terraform workspace new myworkspace
# Select newly created workspace
terraform workspace select myworkspace
```
Resource blocks are the fundamental unit of terraform files, they describe real world infrastructure objects that we can create and manipulate with `resource "resource_location" "resource_alias" {property = "Value"}`. Note that the alias is only used for the current module's (file) scope. Cloud [Providers](https://registry.terraform.io/browse/providers) are interfaces used to interact with a cloud API's, for example AzureRM, AWS, Google, Kubernets or Alibaba. 

**Configuration Files**

* `main.tf`: Defines the resources used by the cloud instance such as a virtual networks, virtual machines, MySQL servers and firewalls.
* `terraform.tfstate`: State file that links the real world resources to the system, keeping metadata updated and improving performance. Can be stored locally or remotely, written in JSON but meant to be interfaced through the terraform configuration files.
* `secrets.tfvars`: Store secret data such as passwords and IP addresses, usually added to gitignore.
* `variable.tf`: Store variable names such as the name of the database.
* `terraform.tfvars`: Vital terraform variables such as Database Source, Resource Group Source and Location Source.

**Azure**

With Terraform you can use DevOps concepts (continuous integration, delivery and deployment) with databases by running SQL script queries from a GitHub repo. To use Terraform in Azure you need to install the Azure CLI, Chocolatey and Terraform through Chocolatey. 

1. Create an Azure Storage Account
2. Create Storage Account Container with Blob public access level (secure the database).
3. Azure DevOps Steps: Create project, pipelines, GitHub, repository, Pipeline YAML:
	1. Use Terraform tasks to add `init`, `validate`, `plan` and `apply`.
	2. Manually add variables to `plan` such as the IP and Password required.
	3. Save and Run will populate the repository using the Terraform pipeline.
4. Use another Pipeline and MySQL Database Deployment to create the storage unit.
5. Make sure that the storage account connection security has access to Azure DevOps. 
6. Once the database instance is running we can commit SQL queries to the repo. 
7. Create another Pipeline to ensure that Python and `mysql.connector` is installed.
	1. We can use this connector to perform unit tests.

```ini
# Azure main.tf example
# Terraform azure cloud provider installation
terraform {
	required_version = ">=0.15"
	required_providers {
		azurerm = {
			source = "hashicorp/azurerm"
			version = ">=2.88.1"
		}
	}
}

provider "azurerm" {
	features {}
}

# Create an azurerm_resource_group resource with an alias, name and location.
resource "azurerm_resource_group" "main" {
	name = "learn-tf-rg-eastus"
	location = "eastus"
}

# Creates virtual network using the previous resource group.
resource "azurerm_virtual_network" "main" {
	name = "learn-tf-vnet-eastus"
	location = azurerm_resource_group.main.location
	resource_group_name = azurerm_resource_group.main.name
	address_space = ["10.0.0.0/16"]
}

# Creates a subnet or IP addresses subset within the virtual network.
resource "azurerm_subnet" "main" {
	name = "learn-tf-subnet-eastus"
	virtual_network_name = azurerm_virtual_network.main.name 
	resource_group_name = azurerm_resource_group.main.name 
	address_prefixes = ["10.0.0.0/24"]
}

# Creates a network interface card (NIC) for the virtual network.
resource "azurerm_network_interface" "internal" {
	name = "learn-tf-nic-eastus"
	location = azurerm_resource_group.main.location
	resource_group_name = azurerm_resource_group.main.name
	ip_configuration {
			name  = "internal"
			subnet_id = azurerm_subnet.main.id
			private_ip_address_allocation = "Dynamic"
	}
}

# Creates a Standard_B1s 2016 windows server virtual machine
resource "azurerm_windows_virtual_machine" "main" {
	name = "learn-tf-vm-eu" 
	resource_group_name = azurerm_resource_group.main.name
	location = azurerm_resource_group.main.location 
	size = "Standard_B1s"
	admin_username = "user.admin" 
	admin_password = "enter-password-here"

	network_interface_ids = [
		azurerm_network_interface.internal.id
	]

	os_disk {
		caching = "ReadWrite"
		storage_account_type = "Standard_LRS"
	}

	source_image_reference {
		publisher = "MicrosoftWindowsServer"
		offer = "WindowsServer"
		sku = "2016-DataCenter"
		version = "latest"
	}
}
```

**AWS**

1. SQS Queue creates our main terraform queue
2. SQS feeds messages to a python lambda function
3. If the lambda function fails it will send a message to a secondary SQS Queue

```ini
# AWS main.tf example
# Terraform aws cloud provider installation
terraform {
	required_version = ">=0.12"
	required_providers {
		aws = {
			source = "hashicorp/aws"
			version = ">=3.26"
		}
	}
}

# Select a region based on the current CLI workspace
variable "aws_region" {
	type = map
	default = {
		dev = "us-east-1"
		prod = "eu-west-2"
	}
}

provider "aws" {
	region = var.aws_region[terraform.workspace]
}

# Zip python script to run it
data "archive_file" "myzip" {
	type = "zip"
	source_file = "main.py"
	output_path = "main.zip"
}

# Asign the Zip code to a AWS Lambda function
resource "aws_lambda_function" "mypython_lambda" {
	filename = "main.zip"
	function_name = "mypython_lambda_test_${terraform.workspace}"
	role = aws_iam_role.mypython_lambda_role.arn
	handler = "main.lambda_handler"
	runtime = "python3.8"
	source_code_hash = "data.archive_file.myzip.output_base64sha256"
}

# Create an AWS role to run the Lambda function
resource "aws_iam_role" "mypython_lambda_role" {
	name = "mypython_role_${terraform.workspace}"
	assume_role_policy = <<EOF
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Action"."sts:AssumeRole",
			"Principal": {
				"Service"."lambda_amazonaws.com"
			},
			"Effect": "Allow",
			"Sid": ""
		}
	]
}
EOF
}

# Main SQS AWS queue to run the Lambda function
resource "aws_sqs_queue" "main_queue" {
	name = "my-main-queue_${terraform.workspace}"
	delay_seconds = 30
	max_message_size = 262144
}

# Secondary SQS in case the Lambda function throws an exception
resource "aws_sqs_queue" "dlq_queue" {
	name = "my-dlq-queue_${terraform.workspace}"
	delay_seconds = 30
	max_message_size = 262144
}

# Use the main SQS queue as the trigger for the Lambda function
resource "aws_lambda_event_source_mapping" "sqs-lambda-trigger" {
	event_source_arn = aws_sqs_queue.main_queue.arn
	function_name = aws_lambda_function.mypython_lambda.arn
}
```

**Resources**

* Azure: https://github.com/LinkedInLearning/terraform-azure-2453108
* AWS: https://github.com/pafable/aws-dev-environment-course 

***

# Google #

**Firebase with Flutter**


Mobile development codebase for iOS and Android using Flutter.

* Flutter https://flutter.dev/ is an app development tool developed by google.
* Firebase is the infrastructure needed to develope a backend with Flutter https://firebase.google.com/docs/flutter/setup
* The main advantages is to have a single code base and native performance (no hacks).
* The most common use of firebase is to create a Cloud Firestore to store user data.
* For Flutter to work correctly we also need to install Android Studio https://developer.android.com/studio
* In Android Studio once an Emmulator or Device is running go to:
	* Preferences - Plugins - Flutter - Restart - New - New Flutter Project
* To provide iOS ports you will need XCode and a MAC computer.
* Firebase Cloud Firestore by default is an NoSQL document database.

***

# SAP #

**S4 Finance Journal with SAP Fiori**

* Accounting staff working with SAP S/4 HANA
* Designed to teach basic SAP end users
* Fiori is the new and more user friendly GUI for managing accounting journals.
* You can also review and audit posted documents and General Ledger reporting
	* Basic Journal Entry: Post Basic General Ledger journals.
	* Manage journal entries: Display, create, post, edit and reverse journals.
	* Recurring Journal entries: Create, edit, list and post recurring journals.
	* Reporting: Financial statement general ledger and account balance.

The newest concept for S4 HANA General Ledger is the use of a Universal Journal.
Ledger specific journals and parallel valuation are other tools not covered.
* Fiori is the new user SAP experience for:
	* Light weight apps, tailored to user tasks
	* SAP transactions with reporting and analytics.
	* Can be used on any device with SAP Fiori app.

For example to enter a General Ledger Journal to record a prepaid expense for a Marketing promotion we will use Fiori Tile that Posts General Journal Entries using the known Master data.

1. Company Code: 1710 (US Company in Palo Alto)
2. Documents Type: SA (General Ledger Account Doc)
3. P and L Account: 65301000 (Marketing Expenses)
4. Cost Center: 1710601 (Marketing)
5. Balance Sheet Account: 12561000 (Prepaid Expenses)
6. Tax Code: I0 (AP Sales Tax 0%)

 If we make a mistake we can reverse a journal entry from the Manage Journal Entry tile.
 On this tile we can also search journals and even create a new journal using another as a template.

***

# Excel #

General Tips:

1. Organize data into simple non breaking tables.
2. Don't add equations such as totals to the tables.
3. Separate complex data into smaller units, for example addresses.
4. Use the correct data format for each column.
5. Data validation constrains are available to check for errors in the data.
6. Use Pick Lists to set available options when inserting new rows.
7. Select the whole table or column by using their name inside brackets.
	1. `=[@Column1] + [@Column2]` or `=sum(TableName[ColumnName])` (outside table)
8. Slicers are advanced filters that show what features are hidden.
	1. They work as dashboards with buttons for each feature selected.

**Form Tool**

Hidden command that allows you to quickly insert new row into a table, it can handle tables with less than 32 columns.

***

Vulnerability is not weakness. The uncertainty, risk and emotional exposure makes us better.
Vulnerability is known your anxieties, questions and concerns about the plan.
Vulnerability is to actively ask questions, have doubts, try new ideas, make mistakes and incorporate others.
The objective is to create trust, collaboration, innovation and motivation.

* Start by saying I don't know, meaning that you know a lot of things but not everything and are willing to learn. Identify what you don't know or have doubts.
* Boldly ask those around you for help and ideas, show that you are a human being and they are in it together.
* Aknowledge uncertenty and what are your worries, this is the start of solving possibilities.
* Finally try something new and fail. Be extremely flexible with your plan, be adaptable and change it if it will produce a better outcome.

***

Certified Cloud Security Professional Exam CCSP

***

General Tools

SQLite
Terraform
vMWARE LABS - vSphere - vCenter - ESXi - VMware

*** 

125 less 30 minutes courses in technology by view count
https://www.linkedin.com/learning/topics/technology?durations=BETWEEN_10_TO_30_MIN&entityType=COURSE&sortBy=POPULARITY&u=76737724


**Power BI: Dashboards for Beginners**


