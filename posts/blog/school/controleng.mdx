---
title: Control Notes
date: '2021-08-15'
tags: ['school', 'control']
---

Analyze, model, design and evaluate closed loop systems for analog processes, including the mathematical basis for control of industrial and automatic systems into their desired performance.

***

**Control System**

Used when we need to modify physical variables into a specific values, they are used in manufacturing, industrial processes or complex tasks, for example the autopilot in a plane. 

![Control Example](/static/images/notes/ControlEngSystemExample.png)

Control systems may or may not have a feedback loop with information that goes back to its origin in order to carry out corrective actions autonomously.

![Control System Components](/static/images/notes/ControlEngSystemComponents.png)

Control Theory can be divided into:

1. Classical Control Theory (Conventional): Automatic control is needed on every engineering field, the first control system was invented by James Watt as a centrifugal speed governor for a steam engine. Minorsky created steering ship controllers in 1922, Nyquist created stability equations for closed loop systems in 1932 and Hazen created servomechanisms for position control in 1934. Fundamentals include:
   1. Frequency Response: Methods developed by Bode (Bode Diagrams) for linear closed loop systems (single Input and single Output), this marked the propagation of PID controllers.
   2. Ziegler and Nichols developed the tuning rules for PID and in 1950 Evans invented the crucial Root Locus method. 
2. Modern Control Theory: Started in 1960 when trying to find optimal control mathematical models interconnected into complex systems with multiple Inputs and Outputs. Digital computer made optimal control (deterministic and stochastic) with complex adaptive and learning control possible by late 1980. Fundamentals include time domain analysis of differential equations and state variable synthesis.
3. Robust Control Theory: Started in 1990 to correct for the sensibility of modern control to the error between the model and the actual system. Robust control uses a range of possible errors and incorporates them into the system as feedback. Fundamentals include time domain analysis with frequency response.

Control Theory terminology:

* Controlled Variable: Quantity to be measured and adjusted by the control system, generally the output (engine speed).
* Control signal: The variable used by the controller in order to adjust the controlled variable (fuel admitted to the engine).
* Control: Measuring the controlled variable and applying the control signal to correct or limit the deviation from its desired value.
* Plant: Equipment or set of machines that work together to perform a particular operation. In control theory its any physical object to be controlled (furnace, reactor, ship, engine).
* Processes: Progressively continuing operation that consists in a series of controlled actions. For control theory its any operation to be controlled (chemical, economic, biological, physical).
* System: Components that act together and perform a certain objective, it can be abstract (physical, biological, economic, mathematical).
* Disturbance: Signal that adversely affects the output of the system, can be internal or external (change in load, human error, lack of resources).
* Feedback: System that in the presence of disturbances maintains a relation between the output and the reference input by comparing them and using their difference as a means of control.
* Servosystem: Feedback system that outputs a physical position, velocity or acceleration in space.
* Automatic Regulation: Feedback system where the desired output is constant or varies slowly in time.

Examples of Control Systems:

1. Speed Control: Speed governor used to set the speed of an engine from the amount of fuel admitted. If the speed drops or increases then change in centrifugal force causes the governor valve to move down or up and therefore decreasing or increasing the fuel admitted until it reaches equilibrium.
2. Temperature Control: Electric furnace with an analog thermometer, converters and a digital controller.
3. Business Control: Each task represents a dynamic element, for smooth flow of work signals we need feedback methods such as progress reports, reduction of delays from cross coupling of groups and statistic based management (lead time). Businesses are closed looped systems with the objective of optimizing managerial control.

![Intro Example Control Sys](/static/images/notes/ControleIntroductoryExampleSyste.png)

Robust Control System steps:

* Obtain a mathematical model of the plant, the controller and the error estimate.
* Each part of the model is a scalar transfer function of the input signal.

$$
\begin{gathered}
	\tilde{G}(s) = \text{Plant}\\
	G(s) = \text{Model}\\
	\Delta(s) = \text{Real Error}\\
	W(s) = \text{Error Estimate}\\
	||\Delta(s)||_\infty < ||W(s)||_\infty = max(0\le w \le \infty) \, |W(jw)|\\
\end{gathered}
$$

* The error estimate $W(s)$ is used to design the transfer function of the plant where $||W(s)||_\infty$ is the max value for $|W(jw)|$ and its called the H infinity norm of $W(s)$.
* The design finishes by finding a controller $K(s)$ where a robust control system inequality such as the next one is satisfied:

$$
\begin{gathered}
	\left|\left| \frac{W(s)}{1+K(s)G(s)} \right|\right|_\infty < 1
\end{gathered}
$$

* There are many inequalities in robust systems that guarantee aspects such as robust stability (Controller guarantees internal stability) or robust performance (Specified performance is satisfied).

**Control System Classification**

* Open Loop Systems: Output without effect on the control action, the reference is a fixed operating condition with accuracy dependent on calibration. For example, a washing machine or traffic lights.
  * No stability problems, easier to build and maintain.
  * Every input is known and there are no significant disturbances.
  * Lower cost, weight, size and power compared to closed loop.
  * Constant recalibration needed to maintain quality.
  * Used if output is hard to measure and use as feedback.

![Control Open System](/static/images/notes/ControlEngOpenSystem.png)

* Closed Loop Systems: Feedback control systems where the actuating error is the difference between the input and the feedback. Furthermore the feedback can be the output itself or a function of the output. For example a room temperature thermostat or human blood pressure.
  * Insensitive to external disturbances and internal parameter variation.
  * Stability is a problem since there may be oscillations when adjusting.
  * Can use inaccurate and inexpensive components from the lack of calibration.

![Control Closed System](/static/images/notes/ControlEngClosedSystem.png)

* Compensation: Modification of the model dynamics to satisfy a given specification, for example root-locus, frequency response, state space and PID with an electronic, pneumatic or hydraulic compensator.
* Performance Specifications: Requirements given in terms of the transient response (maximum overshoot or settling time), steady state (steady state error) or frequency response terms. If they relate to accuracy, stability or response speed they can be given in precise numerical values.
* System Compensation: Setting compensator parameters such as gain is a common way of adjusting the compensation, for example inversing it improves steady state but decreases stability, multiple compensating devices may be needed in order to correct a deficient performance. The most time consuming part of control theory is checking the performance after each parameter adjustment.

Control system characteristics:

* Linear and Non Linear: Most physical systems are nonlinear by nature but if the variation is small enough they can be linearized within a particular range.
* Invariant and Variant Time: Invariant systems have parameters, and therefore responses, that are independent of when the input is applied, an example of a variant system is a rocket since its mass decreases over time from the fuel consumption.
* Continuous and Discrete: The variables in the system can have continuous values or only known at discrete instants.
* SISO and MIMO: Single input and a single output (position controller) or multiple inputs and multiple outputs (complex chemical process).
* Deterministic and Stochastic: Deterministic systems have a unique response to a particular input, therefore they are predictable and repeatable.
* Robust Control: System that incorporates expected disturbances and the incertitude or error of its mathematical model into its feedback loop.
* Adaptatively and Predictive Control: Advanced system that adapts and predicts certain changes in the input and adjusts its mathematical model accordingly.
* Optimal Control: System that evolves in time to find the optimal path for reaching a particular output as the conditions change, an example would be the control of a seeking missile.

***

**Laplace Transform**

* Complex Variable: A complex number $z$ has a real $a$ and an imaginary $b$ part (both constant), in contrast a complex variable $s$ has one or both $\sigma \land \omega$ parts variable. Therefore $s = \sigma + j \omega$.
* Complex Function: A complex function $G(s)$ as a function of $s$ has a real $G_x$ and an imaginary part $G_y$. Therefore $G(s) = G_x + G_y$. Its magnitude is $\sqrt{G_x^2 + G_y^2}$, its angle is $tan^{-1}(G_y/G_x)$ and its conjugate is $G_x - jG_y$.

Complex functions are analytic in a region if the function and all its derivative exist in a region. The derivative of an analytic complex function is defined as:

$$
\begin{gathered}
	\frac{d}{ds} G(s) = \lim_{\Delta s \to 0}\frac{G(s+\Delta s) - G(s)}{\Delta s}= \lim_{\Delta s \to 0} \frac{\Delta G}{\Delta s}
\end{gathered}
$$

It can be shown that if the derivatives taken along two of the infinite paths that $s$ can take to approach zero are equal, in particular $\Delta s = \Delta\sigma$ (parallel to real axis) and $\Delta s = j\Delta\omega$ (parallel to imaginary axis), then the derivative is unique for all paths.

$$
\begin{gathered}
	\lim_{\Delta \sigma \to 0}\frac{\Delta G_x}{\Delta \sigma} + j \frac{\Delta G_y}{\Delta \sigma} = \frac{\delta G_x}{\delta \sigma} + j\frac{\delta G_y}{\delta \sigma}\\
	\lim_{j\Delta \omega \to 0}\frac{\Delta G_x}{j\Delta \omega} + j \frac{\Delta G_y}{j\Delta \omega} = -j\frac{\delta G_x}{\delta \omega} + \frac{\delta G_y}{\delta \omega}\\
\end{gathered}
$$

If both results are equal or if the two conditions (Cauchy-Riemann) are true then we can say that the derivative of the complex function is uniquely determined and therefore analytic.

For example, prove that the following function is analytic:

$$
\begin{gathered}
	G(s) = \frac{1}{s+1}\\
	G(\sigma + j\omega) = \frac{1}{\sigma + j\omega+1} = G_x + jG_y\\
	G_x = \frac{\sigma + 1}{(\sigma + 1)^2 + \omega^2}\\
	G_y = \frac{-\omega}{(\sigma + 1)^2 + \omega^2}
\end{gathered}
$$

Note that with the exception at $s= -1 = (\sigma = -1 \land \omega = 0)$ the function satisfies the conditions and is therefore analytic.

$$
\begin{gathered}
	\frac{\delta G_x}{\delta \sigma} = \frac{\delta G_y}{\delta \omega} = \frac{\omega^2 - (\sigma + 1)^2}{((\sigma + 1)^2 + \omega^2)^2}\\
	-\frac{\delta G_x}{\delta \omega} = \frac{\delta G_y}{\delta \sigma} = \frac{2\omega (\sigma + 1)}{((\sigma + 1)^2 + \omega^2)^2}\\
\end{gathered}
$$

Meaning that its derivative is defined for every value except $s=1$.

$$
\begin{gathered}
	\frac{d}{ds}G(s) = -\frac{1}{(\sigma + j\omega + 1)^2} = -\frac{1}{(s+1)^2} = \frac{d}{ds}\left(\frac{1}{s+1}\right)\\
\end{gathered}
$$

Ordinary points are the points where the function is analytic in the s plane. Singular points are the points where the function is not analytic in the s plane. Poles are singular points where the function or its derivatives approach infinity. Zeros are singular points where the function equals zero.

For example, the next function has $s=-2$ and $s=-10$ as zeros. Simple poles at $s=0 \land s = -1 \land s=-5$. Double pole (Multiple pole of 2th order) at $s=-15$. Also note that this function is zero as $s$ approaches infinity, if we include infinity $s=\infty$ as additional zeros then this function has 5 poles and 5 zeroes in total. 

$$
\begin{gathered}
	G(s) = \frac{K(s+2)(s+10)}{(s)(s+1)(s+5)(s+15)^2}
\end{gathered}
$$

Given a function of time $f(t)$ where $f(t)=0$ for $t<0$ then we define the *laplace transform* and its inverse transformation as:

$$
\begin{gathered}
	\mathcal{L}[f(t)] = \int_0^\infty f(t) e^{-st} dt = F(s)\\
	\mathcal{L}^{-1}[f(t)] = \frac{1}{2\pi j}\int_{c-j\infty}^{c+j\infty} F(s) e^{st} ds = f(t)\\
\end{gathered}
$$

Where $c$ (convergence abscissa) is a constant chosen to be larger than the real parts of every singular point, meaning that the integration path is parallel to the $j\omega$ axis and displaced by a $c$ amount. 

For example, if a control system has a step function as its input function its Laplace transform can be calculated as:

$$
\begin{gathered}
	f(t) = A \quad t\ge 0\\
	F(s) = \int_0^{\infty} (A) e^{-st} dt\\
	u = -st \quad \frac{du}{dt} = -s \quad dt = \frac{du}{-s}\\
	F(s) = \int_0^{\infty} A e^{u} \frac{du}{s}\\
	F(s) = \frac{A}{-s} \int_0^{\infty} e^{u} du = \frac{A}{-s} e^{st} \Big|_0^{\infty}\\
	F(s) = \frac{A}{-s} (0 - 1) = \frac{A}{s}\\
	\therefore F(s) = \frac{A}{s}
\end{gathered}
$$

In practice the inverse laplace transformation is commonly done through partial fraction expansions.

| f(t) | F(s) | f(t) | F(s) |
| :---: | :---: | :---: | :---: |
| $(A)\delta(t)$ | A | $\frac{be^{-bt}-ae^{-at}}{b-a}$ | $\frac{s}{(s+a)(s+b)}$ | 
| $1$ | $\frac{1}{s}$ | $(\frac{1}{ab})(1+\frac{be^{-at}-ae^{-bt}}{a-b})$ | $\frac{1}{(s)(s+a)(s+b)}$ |
| Step A | $\frac{A}{s}$ | $\frac{1-e^{-at}-ate^{-at}}{a^2}$ | $\frac{1}{(s)(s+a)^2}$ |
| $t$ | $\frac{1}{s^2}$ | $\frac{at-a+e^{-at}}{a^2}$ | $\frac{1}{(s)^2(s+a)}$ |
| $t^n$ | $\frac{n!}{s^{n+1}}$ | $\sin(\omega t)$ | $\frac{\omega}{s^2 + \omega^2}$ |
| $\frac{t^{n-1}}{(n-1)!}$ | $\frac{1}{s^n}$ | $\omega t-\sin(\omega t)$ | $\frac{\omega^3}{(s^2)(s^2 + \omega^2)}$ |
| $e^{-at}$ | $\frac{1}{s+a}$ | $\frac{t\sin(\omega t)}{2\omega}$ | $\frac{s}{(s^2 + \omega^2)^2}$ |
| $te^{-at}$ | $\frac{1}{(s+a)^2}$ | $\cos(\omega t)$ | $\frac{s}{s^2 + \omega^2}$ |
| $t^ne^{-at}$ | $\frac{n!}{(s+a)^{n+1}}$ | $1-\cos(\omega t)$ | $\frac{\omega^2}{(s)(s^2 + \omega^2)}$ |
| $\frac{t^{n-1}e^{-at}}{(n+1)!}$ | $\frac{1}{(s+a)^n}$ | $t\cos(\omega t)$ | $\frac{s^2-\omega^2}{(s^2 + \omega^2)^2}$ |
| $e^{-at}\sin(\omega t)$ | $\frac{\omega}{(s+a)^2 + \omega^2}$ | $\sin(\omega t) - \omega t \cos(\omega t)$ | $\frac{2\omega^3}{(s^2 + \omega^2)^2}$ |
| $e^{-at}\cos(\omega t)$ | $\frac{s+a}{(s+a)^2 + \omega^2}$ | $\frac{\sin{\omega t} + \omega t \cos(\omega t)}{2\omega}$ | $\frac{s^2}{(s^2 + \omega^2)^2}$ |
| $\frac{1-e^{-at}}{a}$ | $\frac{1}{(s)(s+a)}$ | $\frac{\cos(\omega_1 t) - \cos(\omega_2 t)}{\omega_2^2 - \omega_1^2}$ | $\frac{s}{(s^2 + \omega_1^2)(s^2 + \omega_2^2)}$ |
| $\frac{e^{-at}-e^{-bt}}{b-a}$ | $\frac{1}{(s+a)(s+b)}$ | $\frac{d \delta(t)}{dt}$ | s |

| Property | Definition |
| :---: | :---: |
| 1 | $\mathcal{L}[A f(t)] = A F(s)$ | 

Four frequently used theorems are the initial value, final value, pulse function and impulse function of the laplace transform:

$$
\begin{gathered}
	\text{Initial Value}\\
	f(0+) = \lim_{t \to 0+}f(t) = \lim_{s \to \infty} (s)(F(s))\\\\
	\text{Final Value}\\
	f(\infty) = \lim_{t \to \infty}f(t) = \lim_{s \to 0} (s)(F(s))\\\\
	\text{Pulse Function}\\
	f(t) = \frac{A}{t_0} (1t) - \frac{A}{t_0} (1 (t-t_0))\\
	\mathcal{L}[f(t)] = \frac{A}{t_0 (s)}-\frac{A}{t_0 (s)}e^{-st_0}\\\\
	\text{Impulse Function}\\
	g(t) = \lim_{t_0 \to 0} \frac{A}{t_0}\\
	\mathcal{L}[g(t)] = \lim_{t_0 \to 0} \frac{A(1-e^{-st_0})}{t_0 (s)}\\
	\mathcal{L}[g(t)] = \frac{\frac{d}{dt_0}A(1-e^{-st_0})}{\frac{d}{dt_0}t_0 (s)} = \frac{A(s)}{s} = A
\end{gathered}
$$

**Partial Fraction Expansion (Distinct Poles)**

Consider $F(S)$ written in its factored form with its poles (A) and zeros (B) as either real or complex numbers (with more zeros $m<n$). The function can be expanded into a sum of simple fractions if it only has *disctinct poles*:

$$
\begin{gathered}
	F(s) = \frac{B(s)}{A(s)} = \frac{K(s+z_1)(s+z_2)\dots(s+z_m)}{(s+p_1)(s+p_2)\dots(s+p_n)}\\
	F(s) = \frac{a_1}{(s+p_1)} + \frac{a_2}{(s+p_2)} + \dots + \frac{a_n}{(s+p_n)}
\end{gathered}
$$

The coefficients $a_k$ of every fraction is the residue at that pole $s=-p_k$. The value of the residue can be found by multiplying both sides of the equation by $(s+p_k)$ with $s=-p_k$:

$$
\begin{gathered}
	\left[(s+p_k)\frac{B(s)}{A(s)}\right] = (s+p_k)\left[\frac{a_1}{(s+p_1)} + \frac{a_2}{(s+p_2)} + \dots + \frac{a_n}{(s+p_n)}\right]\\
	a_k = \left[(s+p_k)\frac{B(s)}{A(s)}\right]_{s=-p_k}\\
	\mathcal{L}^{-1}\left[\frac{a_k}{s+p_k}\right] = a_k e^{p_k t}\\
	\mathcal{L}^{-1}[F(s)] = a_1e^{P_1t} + a_2e^{P_2t} + \dots + a_ne^{P_n t} = f(t)
\end{gathered}
$$

For example, we can obtain the function in time of the following Laplace function using the partial fraction sum method:

$$
\begin{gathered}
	\text{Example 1}\\
	F(s) = \frac{s+3}{(s+1)(s+2)}\\
	f(t) = \frac{a_1}{s+1} + \frac{a_2}{s+2}\\
	a_1 = \left[ \frac{(s+1)(s+3)}{(s+1)(s+2)} \right]_{-1} = \left[ \frac{s+3}{s+2} \right]_{-1} = \frac{-1+3}{-1+2} = 2\\
	a_2 = \left[ \frac{(s+2)(s+3)}{(s+1)(s+2)} \right]_{-2} = \left[ \frac{s+3}{s+1} \right]_{-2} = \frac{-2+3}{-2+1} = -1\\
	F(t) = \frac{2}{s+1} + \frac{-1}{s+2}\\
	f(t) = \mathcal{L}^{-1}\left[\frac{2}{s+1}\right] + \mathcal{L}^{-1}\left[\frac{-1}{s+2}\right]\\
	f(t) = (2)\mathcal{L}^{-1}\left[\frac{1}{s+1}\right] - \mathcal{L}^{-1}\left[\frac{1}{s+2}\right]\\
	\therefore f(t) = (2)e^{-t} - e^{-2t}\\\\
	\text{Example 2}\\
	G(s) = \frac{s^3+5s^2+9s+7}{(s+1)(s+2)}\\
	(s+1)(s+2) = s^2+3s+2\\
	(s^2+3s+2)(s+2) = s^3+5s^2+8s+4\\
	(s^3+5s^2+8s+4)+(s+3) = s^3+5s^2+9s+7\\
	G(s) = \frac{(s+1)(s+2)(s+2)+(s+3)}{(s+1)(s+2)}\\
	G(s) = (s+2)+\frac{(s+3)}{(s+1)(s+2)}\\
	\therefore g(t) = \left(\frac{d}{dt}\delta(t) + 2\delta(t)\right) + (2)e^{-t} - e^{-2t}\\\\
	\text{Example 3}\\
	F(s) = \frac{2s+12}{s^2+2s+5}\\
	s = \frac{-2 \pm \sqrt{4 - (4)(1)(5)}}{2}\\
	s = -1 \pm \frac{\sqrt{-16}}{2} = -1 \pm j\frac{4}{2}\\
	s =  -1 \pm 2j \implies (s+1\pm 2j) = 0\\
	F(s) = \frac{2s+12}{(s+1+2j)(s+1-2j)}\\
	\text{Complex Conjugates - Use Trig}\\
	(s+a)^2 + \omega^2\\
	\text{if} \,\, a = 1 \implies (s+1)^2 = s^2 + 2s + 1\\
	s^2+2s+5 = (s+1)^2 + 4 = (s+1)^2 + 2^2\\
	a = 1 \land \omega = 2\\
	F(s) = \frac{2s+12}{(s+1)^2 + 2^2} = \frac{2(s+1) + 10}{(s+1)^2 + 2^2}\\
	F(s) = \frac{2(s+1)}{(s+1)^2 + 2^2} + \frac{5(2)}{(s+1)^2 + 2^2}\\
	\therefore f(t) = 2e^{-t}\cos(2t) + 5e^{-t}\sin(2t)
\end{gathered}
$$

***

**Partial Fraction Expansion (Multiple Poles)**

We use a similar process to distinct poles where we find (b) constants instead of (a), for example:

$$
\begin{gathered}
	F(s) = \frac{s^2+2s+3}{(s+1)^3}\\
	\frac{B(s)}{A(s)} = \frac{b_1}{(s+1)} + \frac{b_2}{(s+1)^2} + \frac{b_3}{(s+1)^3}\\
	\left[(s+1)^3\frac{B(s)}{A(s)}\right] = (b_1)(s+1)^2 + (b_2)(s+1) + (b_3)\\
	s = -1\\
	(b_1)(0)^2 + (b_2)(0) + (b_3) = \left[(s+1)^3\frac{B(s)}{A(s)}\right]_{s=-1}\\
	b_3 = \left[(s+1)^3\frac{B(s)}{A(s)}\right]_{s=-1}\\
	b_3 = s^2+2+3 = (-1)^2+2(-1)+3 = 2\\
	\frac{d}{ds} \land s = -1\\
	2(b_1)(s+1) + b_2 = \frac{d}{ds}\left[(s+1)^3\frac{B(s)}{A(s)}\right]\\
	2(b_1)(0) + b_2 = \frac{d}{ds}\left[(s+1)^3\frac{B(s)}{A(s)}\right]_{s=-1}\\
	b_2 = \frac{d}{ds}\left[(s+1)^3\frac{B(s)}{A(s)}\right]_{s=-1}\\
	b_2 = \frac{d}{ds}(s^2+2+3) = (2s+2) = 2(-1)+2 = 0\\
	\frac{d^2}{ds^2} \land s = -1\\
	2(b_1) = \frac{d^2}{ds^2}\left[(s+1)^3\frac{B(s)}{A(s)}\right]\\
	b_1 = \frac{1}{2} = \frac{d^2}{ds^2}(s^2+2+3) = \frac{1}{2} (2) = 1\\
	f(t) = \mathcal{L}^{-1}\left[\frac{1}{(s+1)} + \frac{0}{(s+1)^2} + \frac{2}{(s+1)^3}\right]\\
	f(t) = e^{-t} + (2)\left(\frac{1}{(3-1)!}(t^{(3-1)} e^{-(1)t})\right)\\
	f(t) = e^{-t} + \frac{(2)}{2!} t^2 e^{-t}\\
	f(t) = e^{-t} + t^2e^{-t}\\
	\therefore f(t) = e^{-t}(1+t^2)\\
\end{gathered}
$$

We can obtain the partial fraction expansion using Octave. 

$$
\begin{gathered}
	F(s) = \frac{B(s)}{A(s)} = \frac{b_0s^n + b_1s^{n-1} + \dots + b_n}{s^n + a_1s^{n-1} + \dots + a_n}\\
	\frac{B(s)}{A(s)} = \frac{r(1)}{s-p(1)} + \frac{r(2)}{s-(2)} + \dots + \frac{r(n)}{s-p(n)} + k(s)\\
	\therefore p(n) = -p_n \land r(n) = a_n\\\\
	\text{Example 1}\\
	G(s) = \frac{2s^3+5s^2+3s+6}{s^3+6s^2+11s+6}\\
	G(s) = \frac{-6}{s+3} + \frac{-4}{s+2} + \frac{3}{s+1} + 2\\\\
	\text{Example 2}\\
	G(s) = \frac{s^2+2s+3}{(s+1)^3}\\
	G(s) = \frac{s^2+2s+3}{s^3+3s^2+3s+1}\\
	G(s) = \frac{1}{s+1} + \frac{0}{(s+1)^2} + \frac{2}{(s+1)^3}\\
\end{gathered}
$$

```matlab
% num = [b0, b1, ... , bn]
% den = [1, a1, ... , an]
% [residues, poles, kterms] = residue(num, den)

num = [2 5 3 6]
den = [1 6 11 6]
[r,p,k] = residue(num,den)
r = [-6, -4, 3]
p = [-3, -2, -1] 
k = 2

num = [0 1 2 3]
den = [1 3 3 1]
[r,p,k] = residue(num,den)
r = [1, 0, 2]
p = [-1, -1, -1] 
k = 0
```

**Mathematical Modeling**

The mathematical model is a set of differential equations that represent the dynamics (mechanical, electrical, thermal, biological, etc) of the system, different systems can be represented by the same set of equations. Generally we assume causal models where the output depends on past inputs but remains independent of future inputs. Optimal control systems tend to use state space models and transient or frequency response SISO-linear-time-invariant control systems tend to use transfer functions. 

Models always compromise simplicity with accuracy, a common example is the use of linear-lumped-parameter models (ordinary D.E.) where we ignore some of the nonlinear and distributed parameters with small responses, with this simple model if we need more accuracy we can adjust its complexity accordingly. 

An ordinary D.E. model tends to be accurate only for low frequency applications, for example the mass of a sprint in a spring-load system can't be ignored at high enough frequencies. Linear systems can use the superposition principle where the response from two inputs can be represented as the sum of the two individual responses. Time invariant systems have D.E. models were their coefficients are constants or functions of the independent variable.

**Ordinary Differential Equation Model**

For example, given the following ordinary D.E. model and assuming that the starting conditions are a pair of unkown constants (position and velocity) calculate its corresponding time function for the dependent variable position (x):

$$
\begin{gathered}
	\ddot{x} + 3\dot{x} +2x = 0 \quad x(0) = a \quad \dot{x}(0) = b\\
	\left(\frac{dx^2(t)}{dt^2}\right) + \left(3 \frac{dx(t)}{dt}\right) + \left( 2x(t)\right) = 0\\\\
	\text{Laplace Derivatives}\\
	\mathcal{L}\left(\frac{dx^2(t)}{dt^2}\right) + \mathcal{L}\left(3 \frac{dx(t)}{dt}\right) + \mathcal{L}\left( 2x(t)\right) = 0\\
	\left(s^2X(s)-sx(0)-x(0)\right) + 3\left(sX(s) - x(0)\right) + 2X(s) = 0\\
	s^2X(s) - sa - b + 3(sX(s) - a) + 2X(s) = 0\\
	X(s)(s^2+3s+2) = as + b + 3a\\
	X(s) = \frac{as + 3a +b}{s^2 + 3s + 2}\\
	x(t) = \mathcal{L}^{-1}[X(s)] = \frac{as+b+3a}{(s+1)(s+2)}\\\\
	\text{Distinct Poles}\\
	x(s) = \frac{a_1}{s+1} + \frac{a_2}{s+2}\\
	a_1  = \left[ \frac{as+b+3a}{s+2} \right]_{-1} = \frac{-a+b+3a}{-1+2} = 2a+b\\
	a_2  = \left[ \frac{as+b+3a}{s+1} \right]_{-2} = \frac{-2a+b+3a}{-2+1} = -a-b\\
	x(s) = \frac{2a +b}{s+1} + \frac{-a-b}{s+2}\\
	x(t) = (2a +b) \mathcal{L}^{-1}(\frac{1}{s+1}) + (-a-b) \mathcal{L}^{-1}(\frac{1}{s+2})\\
	\therefore \quad x(t) = (2a+b)(e^{-t}) + (-a-b)(e^{-2t})
\end{gathered}
$$

**Transfer Function**

Transfer functions characterize the input and output relationships of the system components in the form of differential equations. For a linear, time-invariant system with *zero initial conditions* its the ratio between the Laplace of the output (response) and the Laplace of the input (driving).

$$
\begin{gathered}
	a_0y^n + a_1y^{n-1} + \dots + a_n y = b_0x^m + b_1x^{m-1} + \dots + b_m x, \quad n \ge m\\
	G(s) = \frac{\mathcal{L}[y(s)]}{\mathcal{L}[x(s)]} = \frac{Y(s)}{X(s)} = \frac{b_0S^m + b_1S^{m-1} + \dots + b_{m-1}S + b_m }{a_0S^n + a_1S^{n-1} + \dots + a_{n-1}S + a_n}\\
	Y(s) = G(s) X(s) \implies G(s) = \frac{Y(s)}{X(s)}
\end{gathered}
$$

The transfer function is independent of the natura and magnitude of the input and represents the system response using complex functions. The system is an nth order system if the highest power of in the denominator is equal to n. The product between of the input (Y) and the transfer function (G) is a convolution in time therefore the Laplace is given as:

$$
\begin{gathered}
	y(t) = \int^t_0 x(\tau)g(t-\tau) d\tau = \int^t_0 g(\tau)x(t-\tau) d\tau\\
	\text{For Unit Impulse Input}\\
	Y(s) = G(s) \implies \mathcal{L}^{-1}[G(s)] = g(t) 
\end{gathered}
$$

The impulse response function (g) for a unit impulse input is also called the weighting function of the system.

For example, find the transfer function and the response to the unitary step of the following circuit:

![Control Transfer Example System](/static/images/notes/ControlEngCircuitTransferExample.png)

$$
\begin{gathered}
	G(s) = \frac{E_o(s)}{E_i(s)}\\
	\text{Resistor Current}\\
	I = \frac{V}{R} \implies i(t) = \frac{e_i(t) - e_o(t)}{R}\\
	I(s) = \frac{E_i(s) - E_o(s)}{R}\\
	\text{Capacitor Voltage}\\
	V = \frac{1}{C} \int I dt \implies e_o(t) = \frac{1}{C} \int i(t) dt\\
	E_o(s) = \frac{1 I(s)}{C s}\\
	\text{Input and Output Ratio}\\
	E_o(s) = \frac{1}{Cs} \left( \frac{E_i(s) - E_o(s)}{R} \right)\\
	E_o(s) = \frac{E_i(s)}{RCs} - \frac{E_o(s)}{RCs}\\
	\frac{E_i(s)}{RCs} = \frac{E_o(s)}{RCs} + E_o(s)\\
	\frac{E_i(s)}{RCs} = E_o(s) \left(\frac{1}{RCs} + 1\right)\\
	\frac{E_i(s)}{E_o(s)} = RCs\left(\frac{1}{RCs} + 1\right)\\
	\frac{E_i(s)}{E_o(s)} = 1 + RCs \implies \frac{E_o(s)}{E_i(s)} = \frac{1}{RCs + 1}\\
	\text{Transfer Function}\\
	G(s) = \frac{E_o(s)}{E_i(s)} = \frac{1}{RCs + 1}\\
	\text{Unitary Step Response}\\
	E_o(s) = \frac{1}{RCs + 1} \left(\frac{1}{s}\right)\\
	e_o(t) = \frac{1}{RC} (e^{-t/(RC)}) (1)\\
	e_o(t) = \frac{1}{(1000*0.0005)} (e^{-t/(1000*0.0005)}) (1) \\
	e_o(t) = 2e^{-2t}\\
\end{gathered}
$$

```matlab
% Calculate voltage using RC transfer function
pkg load control
pkg load symbolic
R = 1e3
C = 500e-6
G = tf( [1] , [R*C 1] )
s = tf('s')
X = 1/s
Y = G*X

ilaplace(sym("1/(0.5*s+1)"))

% Numerical Representation Impulse
impulse(G)
% Numerical Representation Step
step(G)
% Transfer Function Frequency Response
bode(G)
```

***


**Block Diagram**

System of pictorial representation of each transfer function (G) performed by each component, its main purpose is to show the input signal flow through the system as arrows. All variables are linked through unidirectional functional blocks. It allows to evaluate the contribution of each component to the overall performance.

![Control Block Diagram](/static/images/notes/ControlEngBlockDiagram.png)

For closed loop systems generally the output (C) must be measured and then converted by a transfer function (H) into the same units as the reference (R) before executing a comparison operation. Note that the output for a simple closed loop system depends on the Closed Loop Transfer Function and the nature of the input.

$$
\begin{gathered}
	\text{Open Loop Transfer Function}\\
	\frac{B(s)}{E(s)} = G(s) H(s)\\
	\text{Feedforward Transfer Function}\\
	\frac{C(s)}{E(s)} = G(s)\\
	\text{Closed Loop Transfer Function}\\
	C(s) = G(s)E(s)\\
	E(s) = R(s) - B(s) = R(s) - (H(s)C(s))\\
	C(s) = G(s)(R(s) - (H(s)C(s)))\\
	\frac{C(s)}{R(s)} = \frac{G(s)}{1 + G(s)H(s)}\\
	C(s) = \frac{G(s)}{1 + G(s)H(s)} R(s)
\end{gathered}
$$

![Control Block Disturbances](/static/images/notes/ControlDisturbancesBlockDiagram.png)

We can add disturbances (D) to a closed loop transfer function. In this case we consider additional inputs such as (D) independently of (R) with the superposition of their outputs (CR and CD) as the final output (C) of the system:

$$
\begin{gathered}
	C(s) = C_R(s) + C_D(s)\\
	C(s) = \frac{G_2(s)}{1 + G_1(s)G_2(s)H(s)} (G_1(s)R(s) + D(s))
\end{gathered}
$$

Suppose we have a suspension system based on a spring with constant (k), a load of mass (m) and a hydraulic shock absorber with a friction coefficient (b). While applying a force (u) to the mass the system responds with a position of the mass (y). The result is the combined effect of the spring and the shock absorber. Using newton's laws we can model the transfer function:

$$
\begin{gathered}
	F=ma\\
	u-(ky)-b\left(\frac{dy}{dt}\right) = (m)\left(\frac{d^2 y(t)}{dt^2}\right)\\
	u = (m)\left(\frac{d^2 y(t)}{dt^2}\right) + b\left(\frac{dy}{dt}\right) + ky\\
	u = m\ddot{y} + b\dot{y} + ky\\
	U(s) = ms^2Y(s) + bsY(s) + kY(s)\\
	U(s) = Y(s)(ms^2 + bs + k)\\
	G(s) = \frac{Y(s)}{U(s)} = \frac{1}{ms^2 + bs + k}
\end{gathered}
$$

The force of the spring and the force of the shock absorber oppose the input force. The input makes the spring move by a certain constant value, it makes the shock absorber move at certain velocity and makes the mass move at a certain acceleration.

This transfer function can be represented in a block diagram as a simple open system with one input and one output. With block diagrams we can represent multiple transfer functions and combine them with multiple inputs and outputs.

![Control Block Example](/static/images/notes/ControlEngCircuitExampleBlock.png)

**Block Diagram Simplification**

![Block Simplification](/static/images/notes/ControlEngBlockSimplification.png)

![Block SimplificationExample](/static/images/notes/ControlEngBlockSimplificationExample.png)

The three most common block interactions are transfer functions in series, in parallel or in a feedback loop. We can calculate them in Octave:

$$
\begin{gathered}
	G_1(s) = \frac{10}{s^2+2s+10}\\
	G_2(s) = \frac{5}{s+5}\\
	G_3(s) = \frac{50}{s^3+7s^2+20s+50}\\
	G_4(s) = \frac{5s^2+30s+100}{s^3+7s^2+20s+50}\\
	G_5(s) = \frac{10s+50}{s^3+7s^2+20s+100}
\end{gathered}
$$

```matlab
pkg load control
num1 = [10];
den1 = [1 2 10];
G1 = tf(num1, den1)
num2 = [5];
den2 = [1 5];
G2 = tf(num2, den2)

% Calculate cascaded (Serial) T.F.
G3 = series(G1, G2)
[num3, den3] = tfdata(G3, 'v');

% Calculate parallel T.F.
G4 = parallel(G1, G2)
[num4, den4] = tfdata(G4, 'v');

% Calculate feedback Closed Loop T.F.
G5 = feedback(G1, G2)
[num5, den5] = tfdata(G5, 'v');
```

**Industrial Controllers**

Automatic or industrial controllers compare the actual value of the output with the reference input, determines the error and produces a control signal that will reduce the deviation. The control action is the method used to produce the control signal. For example, in a water level control system (Two-Position Controller) the output (u) can follow one of two exponential curves, one for filling and the other for emptying, the controller makes (u) oscillate inside the differential gap. Reducing the gap decreases the oscillation amplitude (better accuracy) at the cost of increasing the On-Off cycles.

![Automatic Control System Industry](/static/images/notes/ControlAutomaticControlSystem.png)

1. Two-position or on–off controllers: The actuating element has two fixed positions. If (u) is the output and (e) is the actuating error then (u) will remain at a maximum (U1) or minimum (U2). The differential gap is the range through which the error signal must pass before the switch occurs. 
   * $u(t) = U_1, e(t) > 0 \land u(t) = U_2 , e(t) < 0$
2. Proportional controllers: When there is a proportional (K) relation (gain) between the output (u) and the actuating error (e). Its essentially an amplifier with an adjustable gain.
   * $u(t) = K_p \, e(t) \implies \frac{U(s)}{E(s)} = K_p$
3. Integral controllers: The output (u) changes at a given rate (differential) that is proportional (K) to the actuating error (e).
   * $\frac{du(t)}{dt} = K_i \, e(t)$ 
   * $u(t) = K_i \int^t_0 e(t) dt$
   * $\frac{U(s)}{E(s)} = \frac{K_i}{s}$
4. Proportional-Integral controllers: Addition of a integral time constant (Ti) to the integral part.
   1. $u(t) = K_p\, e(t) + \frac{K_i}{T_i} \int^t_0 e(t) dt$
   2. $\frac{U(s)}{E(s)} = K_p (1 + \frac{1}{T_i s})$
5. Proportional-Integral-Derivative controllers (PID): Addition of a derivative time constant (Td) to the derivative part.
   1. $u(t) = K_p\, e(t) + K_iT_d \frac{de(t)}{dt}$
   2. $\frac{U(s)}{E(s)} = K_p (1 + T_d s)$
6. Proportional-Integral-Derivative controllers: Also known as PID's, they have the advantages of every control action.
   1. $u(t) = K_p\, e(t) + \frac{K_i}{T_i} \int^t_0 e(t) dt + K_iT_d \frac{de(t)}{dt}$
   2. $\frac{U(s)}{E(s)} = K_p (1 + \frac{1}{T_i s} + T_d s)$

***

**Signal Flow Graph**

Alternate form to represent a control system, it consists of a network of nodes connected by branches. Each node is a system variable or signal and each branch is a multiplier or transmittance, the multiplication factor and direction is indicated. 

1. A branch indicates functional dependence of one signal to another.
2. A node sums every input branch and transmits the sum to every output branch.
3. A mixed node can be considered an output node by adding a unitary output branch.

To obtain the transfer function of a system we can simplify its signal flow graph or use the Mason's Gain Formula:

$$
\begin{gathered}
	P = \frac{1}{\Delta} \sum_k P_k \Delta_k
\end{gathered}
$$

In Mason's formula we have $k$ as the number of direct paths, $P_k$ as the path gain of the kth direct path, $\Delta$ as the determinant of graph $1-\sum_aL_a +\sum_{bc}L_bL_c - \dots$ (each sum from disjoint loop combinations) and $\Delta_k$ as the determinant cofactor of the kth direct path with the loops that touch it eliminated from the series.

$$
\begin{gathered}
	\text{Independent Loops}\\
	L_1 = G_1 G_2 H_1\\
	L_2 = -G_1 G_2 G_3\\
	L_3 = -G_2 G_3 H_2\\
	\text{Search Disjoint Combinations}\\
	(L_1L_2), (L_1L_3), (L_2L_3), (L_1L_2L_3)\\
	\text{No Disjoint Combinations}\\
	\text{Determinant}\\
	\Delta = 1 - (L_1 + L_2 + L_3) + (0) - (0)\\
	\text{Direct Paths}\\
	k = 1\\
	P_1 = G_1 G_2 G_3\\
	\text{Delete Loops That Touch Any D.P.}\\
	[L_1, L_2, L_3] = 0\\
	\text{Cofactors}\\
	\Delta_1 = 1 - (0 + 0 + 0) + (0) - (0) = 1\\
	P = \frac{1}{1 - (L_1 + L_2 + L_3)} \sum_1 (G_1 G_2 G_3) (1)\\
	P = \frac{G_1G_2G_3}{1 - G_1G_2H_1 + G_1G_2G_3 + G_2G_3H_2}
\end{gathered}
$$

![Block SimplificationExample](/static/images/notes/ControlEngSignalFlowExample.png)

* Input Node $(R)$: Only has branches coming out.
* Output Node $(C)$: Only has branches coming in. 
* Mixed Node $(E1)$: Has input and output branches.
* Open Path $(E1-E2-S1)$: Path to another node without crossing a node twice.
* Closed Path $(S2-S3-C-S2)$: Loop or path to the same node without crossing a node twice.
* Loop Gain $(G2-G3-(-H2))$: Product of the transmittances in a closed path or loop.
* Disjoint Loop $(L1L2)$: Group of loops with NO common node between them.
* Direct Path: Path from an input to an output node without crossing a node twice.
* Direct Path Gain $(G1-G2-G3)$: Product of the transmittances in a direct path.

***

**State Space Modeling**

Modern control theory focuses on complex MIMO tasks with great accuracy by describing the system with states in the time or frequency domain. A state is the minimum set of state variables such that given the time zero conditions and the input the output will be deterministic. States can be quantitative or qualitative, for measurable states we can apply optimal control laws (weighted state variable feedback).

State variables are grouped into state vectors that fully describe a system state at any time point. The state space is a n dimensional space where every state variable acts as a dimension, meaning that every state can be represented as a point. State space models account for input variables, output variables and state variables.

Systems must have elements that memorize how the input behaves after time zero, integrators can serve as memory devices in a continuous time. The outputs of integrators are the state variables that define the internal system state, therefore the number of state variables is equal to the number of integrators.

Assuming that a MIMO system has $n$ integrators with $u_r(t)$ inputs and $y_m(t)$ outputs then if we define the integrator outputs as state variables $x_n(t)$ we can fully describe the system with state equations:

$$
\begin{gathered}
	\dot{x}_1(t) = f_1(x_1,x_2, \dots, x_n; u_1, u_2, \dots, u_r; t)\\
	\dot{x}_2(t) = f_2(x_1,x_2, \dots, x_n; u_1, u_2, \dots, u_r; t)\\
	\dots\\
	\dot{x}_n(t) = f_n(x_n; u_r; t)
\end{gathered}
$$

From the state equations we can see that the output equations will be:

$$
\begin{gathered}
	y_1(t) = g_1(x_1,x_2, \dots, x_n; u_1, u_2, \dots, u_r; t)\\
	y_2(t) = g_2(x_1,x_2, \dots, x_n; u_1, u_2, \dots, u_r; t)\\
	\dots\\
	y_n(t) = g_n(x_n; u_r; t)
\end{gathered}
$$

If every state equation is linear or is linearizable their linear equation representation is:

$$
\begin{gathered}
	\dot{x}(t) = A(t)x(t) + B(t)u(t)\\
	y(t) = C(t)x(t) + D(t)u(t)\\
\end{gathered}
$$

Where (A) is the states, (B) is the inputs, (C) the outputs and (D) the direct drive. When working with time invariant systems (f and g constant) we can simplify further as:

$$
\begin{gathered}
	\dot{x}(t) = Ax(t) + Bu(t)\\
	y(t) = Cx(t) + Du(t)\\
\end{gathered}
$$

Note that in most physicals systems the direct drive matrix can be ignored since it represents a positive feedback loop.

![State Space](/static/images/notes/ControlStateSpaceRep.png)


$$
\begin{gathered}
	\dot{x}(t) = Ax(t) + Bu(t)\\
	y(t) = Cx(t) + Du(t)\\
\end{gathered}
$$

For example, assume a linear mechanical system whit an external input force $u(t)$ and an output displacement of the mass $y(t)$. The displacement is at equilibrium at time zero since $u(0)=0$. From the equation we can observe that the system is of second order meaning that it involves two integrators and two state variables $x_1(t) \land x_2(t)$.

![TwoIntegrators](/static/images/notes/ControlMechanicalSystemTwoInt.png)

$$
\begin{gathered}
	F=ma\\
	u-(ky)-b\left(\frac{dy}{dt}\right) = (m)\left(\frac{d^2 y(t)}{dt^2}\right)\\
	u = (m)\left(\frac{d^2 y(t)}{dt^2}\right) + b\left(\frac{dy}{dt}\right) + ky\\
	u = m\ddot{y} + b\dot{y} + ky\\
	x_1(t) = y(t) \quad x_2(t) = \dot{y}(y)\\
	\text{First State Equation}\\
	\dot{x}_1 = x_2\\
	\text{Second State Equation}\\
	u = m\ddot{y} + b \dot{y} + ky\\
	\frac{u}{m} = \ddot{y} + \frac{b}{m}\dot{y} + \frac{k}{m}y \\
	\ddot{y} =  - \frac{b}{m}\dot{y} - \frac{k}{m}y + \frac{u}{m}\\
	\dot{x}_2 =  - \frac{b}{m}x_2 - \frac{k}{m}x_1 + \frac{u}{m}\\
	\text{Output Equation}\\
	x_1(t) = y(t) \implies y = x_1\\
	\text{Vector Matrix Form}\\
	\begin{bmatrix} \dot{x}_1\\ \dot{x}_2 \end{bmatrix}=
	\begin{bmatrix} 0 & 1\\ -\frac{k}{m} & -\frac{b}{m} \end{bmatrix}
	\begin{bmatrix} x_1\\ x_2 \end{bmatrix} +
	\begin{bmatrix} 0\\ \frac{1}{m} \end{bmatrix} u \\ 
	y = \begin{bmatrix} 1 & 0 \end{bmatrix} \begin{bmatrix} x_1\\ x_2 \end{bmatrix}\\
	A = \begin{bmatrix} 0 & 1\\ -\frac{k}{m} & -\frac{b}{m} \end{bmatrix},
	B = \begin{bmatrix} 0\\ \frac{1}{m} \end{bmatrix},
	C = \begin{bmatrix} 1 & 0 \end{bmatrix},
	D = 0
\end{gathered}
$$

There is a direct correlation between the state space equations and the transfer function that applies for SISO (Transfer Scalar) and MIMO (Transfer Matrix) systems:

$$
\begin{gathered}
	G(s) = \frac{Y(s)}{U(s)}\\
	\dot{x} = Ax+Bu\\
	y = Cx + Du\\
	(sX(S) - x(0)) = AX(s) + BU(s)\\
	Y(s) = CX(s) + DU(s)\\
	sX(S) = AX(s) + BU(s)\\
	(sI - A)X(s) = BU(s)\\
	X(s) = \frac{BU(s)}{(sI - A)}\\
	Y(s) = C\frac{BU(s)}{(sI - A)} + DU(s)\\
	Y(s) = [\frac{CB}{(sI - A)} + D]U(s)\\
	G(s) = \frac{CB}{(sI - A)} + D \quad D = 0\\
	G(s) = \frac{Q(s)}{|sI - A|} = C(sI-A)^{-1}B
\end{gathered}
$$

Note that $|sI - A|$ is the characteristic polynomial of G(s) meaning that the eigenvalues of A are identical to the poles of G(s). Applying the correlation to the mechanical example we have:

$$
\begin{gathered}
	\text{Using Laplace}\\
	u = m\ddot{y} + b\dot{y} + ky\\
	U(s) = ms^2Y(s) + bsY(s) + kY(s)\\
	U(s) = Y(s)(ms^2 + bs + k)\\
	G(s) = \frac{Y(s)}{U(s)} = \frac{1}{ms^2 + bs + k}\\
	\text{Using the Correlation}\\
	\begin{bmatrix} \dot{x}_1\\ \dot{x}_2 \end{bmatrix}=
	\begin{bmatrix} 0 & 1\\ -\frac{k}{m} & -\frac{b}{m} \end{bmatrix}
	\begin{bmatrix} x_1\\ x_2 \end{bmatrix} +
	\begin{bmatrix} 0\\ \frac{1}{m} \end{bmatrix} u \\ 
	y = \begin{bmatrix} 1 & 0 \end{bmatrix} \begin{bmatrix} x_1\\ x_2 \end{bmatrix}\\
	G(s) = \begin{bmatrix} 1 & 0 \end{bmatrix}
	\left[ \begin{bmatrix} s & 0\\ 0 & s \end{bmatrix} - \begin{bmatrix} 0 & 1\\ -\frac{k}{m} & -\frac{b}{m} \end{bmatrix} \right] ^{-1} \begin{bmatrix} 0\\ \frac{1}{m} \end{bmatrix}\\
	G(s) = \begin{bmatrix} 1 & 0 \end{bmatrix}
	\begin{bmatrix} s & -1\\ \frac{k}{m} & \frac{b}{m}+s \end{bmatrix}^{-1} \begin{bmatrix} 0\\ \frac{1}{m} \end{bmatrix}\\
	G(s) = \begin{bmatrix} 1 & 0 \end{bmatrix} \begin{bmatrix} \frac{b}{m}+s & 1\\ -\frac{k}{m} & s \end{bmatrix} \left(\frac{1}{s^2 + \frac{b}{m}s + \frac{k}{m}}\right) \begin{bmatrix} 0\\ \frac{1}{m} \end{bmatrix}\\
	G(s) = \begin{bmatrix} \frac{b}{m}+s & 1 \end{bmatrix} \begin{bmatrix} 0\\ \frac{1}{m} \end{bmatrix} \left(\frac{1}{s^2 + \frac{b}{m}s + \frac{k}{m}}\right) \\
	G(s) = \frac{1}{m}\left(\frac{1}{s^2 + \frac{b}{m}s + \frac{k}{m}}\right)\\
	G(s) = \frac{1}{ms^2 + bs + k}
\end{gathered}
$$

**S.S. of N Order without Derivatives in the F.F.**

A system with finite lumped elements may be described by ordinary D.E. (time as the independent variable). The D.E. can be represented with vector-matrix notation and if (n) elements are state variables it is considered a valid state equation. If the state equations have the next characteristics we can generalize their vector-matrix notation:

1. There are no derivative terms in Forcing Function (Input u).
2. The knowledge at the starting conditions and the input determines the system.
3. Every output can be modeled as (n) state variables in time.

$$
\begin{gathered}
	y^n + a_1y^{n-1} + \dots + a_{n-1}\dot{y} + a_ny = u\\
	y(t), \dot{y}(t), \dots, y^{n-1}(t) = x_n(t)\\
	x_1 = y \quad x_2 = \dot{y} \quad x_n = y^{n-1}\\
	\dot{x}_1 = x_2 \quad \dot{x}_2 = x_3 \quad \dot{x}_{n-1} = x_n\\
	\dot{x}_n = -a_nx_1 - \dots - a_1x_n + u\\
	x = \begin{bmatrix} x_1\\ x_2\\ \dots\\ x_n \end{bmatrix}\\
	A = \begin{bmatrix} 0 & 1 & 0 & \dots & 0\\ 0 & 0 & 1 & \dots & 0\\ 0 & 0 & 0 & \dots & 1\\ -a_n & -a_{n-1} & -a_{n-2} & \dots & -a_{1}\\ \end{bmatrix}\\
	B = \begin{bmatrix} 0\\ 0\\ \dots\\ 1 \end{bmatrix}\\
	y = \begin{bmatrix} 1 & 0 & \dots & 0 \end{bmatrix}
	\begin{bmatrix} x_1\\ x_2\\ \dots\\ x_n \end{bmatrix} = Cx\\
	G(s) = \frac{1}{s^n + a_1s^{n-1}+ \dots + a_{n-1}s+a_n}
\end{gathered} 
$$

![No Derivative Terms](/static/images/notes/ControlNoDerivativeTerms.png)

***

**S.S. of N Order with Derivatives in the F.F.**

If there are derivative terms in the forcing function (input u) we need to define the state variables in such a way that they eliminate the derivatives, therefore:

$$
\begin{gathered}
	y^n + a_1y^{n-1} + \dots + a_{n-1}\dot{y} + a_ny \\= b_0u^n + b_1u^{n-1} + \dots + b_{n-1}\dot{u} + b_nu\\
	\beta_0 = b_0\\
	\beta_1 = b_1 - a_1\beta_0\\
	\beta_2 = b_2 - a_1\beta_1 - a_2\beta_0\\
	\beta_n = b_n - a_1\beta_{n-1} - \dots - a_{n-1}\beta_1 - a_{n}\beta_0\\
	x_1 = y-\beta_0u\\
	x_2 = \dot{y}-\beta_0\dot{u}-\beta_1u = \dot{x}_1-\beta_1u\\
	x_3 = \dot{y}-\beta_0\ddot{u}-\beta_1\dot{u}-\beta_2u = \dot{x}_2-\beta_2u\\
	x_n = y^{n-1}-\beta_0u^{n-1}-\dots -\beta_{n-1}u= \dot{x}_{n-1}-\beta_{n-1}u\\
	\dot{x}_1 = x_2+\beta_1u \quad \dot{x}_2 = x_3+\beta_2u \quad \dot{x}_{n-1} = x_n+\beta_{n-1} u\\
	\dot{x}_n = -a_nx_1 - \dots - a_1x_n + \beta_n u\\
	x = \begin{bmatrix} x_1\\ x_2\\ \dots\\ x_n \end{bmatrix} \quad B = \begin{bmatrix} \beta_1 \\ \beta_2 \\ \dots\\ \beta_n \end{bmatrix}\\
	A = \begin{bmatrix} 0 & 1 & 0 & \dots & 0\\ 0 & 0 & 1 & \dots & 0\\ 0 & 0 & 0 & \dots & 1\\ -a_n & -a_{n-1} & -a_{n-2} & \dots & -a_{1}\\ \end{bmatrix}\\
	C = \begin{bmatrix} 1 & 0 & \dots & 0 \end{bmatrix} \quad D = \beta_0 = b_0\\
	y = \begin{bmatrix} 1 & 0 & \dots & 0 \end{bmatrix}
	\begin{bmatrix} x_1\\ x_2\\ \dots\\ x_n \end{bmatrix} + B_0u\\
	G(s) = \frac{b_0s^n + b_1s^{n-1}+ \dots + b_{n-1}s+b_n}{s^n + a_1s^{n-1}+ \dots + a_{n-1}s+a_n}
\end{gathered} 
$$

![With Derivative Terms](/static/images/notes/MechanicalWithoutDerivativesControlExamp.png)

**Transfer Function to State Space**

For a given transfer function there are infinitely many possible state space representations. There are canonical representations such as controllable, observable, diagonal and Jordan. We can obtain one of this valid representations using Octave:

$$
\begin{gathered}
	\frac{Y(s)}{U(s)} = \frac{s}{(s+10)(s^2+4s+16)}\\
	\frac{Y(s)}{U(s)} = \frac{s}{s^3+14s^2+56s+160}\\
	\begin{bmatrix} \dot{x_1}\\ \dot{x_2}\\ \dot{x_3}
	\end{bmatrix} = 
	\begin{bmatrix} 0 & 0 & -1.6\\ -10 & 0 & 5.6\\ 0 & -10 & -15
	\end{bmatrix}
	\begin{bmatrix} x_1\\ x_2\\ x_3 \end{bmatrix}+
	\begin{bmatrix} 0\\ 0.1\\ 0 \end{bmatrix} (u)\\
	y = 
	\begin{bmatrix} 0 & 0 & -1 \end{bmatrix}
	\begin{bmatrix} x_1\\ x_2\\ x_3 \end{bmatrix}+(0)(u)
\end{gathered}
$$


```matlab
% Wolovich's Observable companion form used
pkg load signal
num = [1 0];
den = [1 14 56 160];
[A,B,C,D] = tf2ss(num,den)

% From state space to transfer function
[num1,den1] = ss2tf(A,B,C,D)

% Second example
A = [0 1 0; 0 0 1; -5 -25 -5];
B = [0; 25; -120];
C = [1 0 0];
D = [0];
[num2,den2] = ss2tf(A,B,C,D)
```

**Linearization of Nonlinear Models**

Nonlinear systems can't be described using the superposition principle, therefore the response of two or more outputs cannot be treated separately. In the real world all systems are nonlinear but thankfully most behave linearly for a given parameter range.

However outside the operating range components may saturate for large inputs or be insensitive (dead spaces) for small signals. Square-Law nonlinearity may occur for example in dampers at high velocities where the damping force becomes proportional to the square of the velocity.

The most basic linearization method involves control systems that have an equilibrium point and relatively small inputs signals around it. The method is based on the expansion of a nonlinear function into a Taylor series around the operating point $(\bar{x},\bar{y})$ and ignoring high order (third derivative) Taylor series terms.

$$
\begin{gathered}
	y = f(x)\\
	y = f(\bar{x}) + \frac{df(x-\bar{x})}{dx} + \frac{1}{2!}\frac{d^2f(x-\bar{x})^2}{dx^2} + \dots\\
	y = \bar{y} + K (x-\bar{x})\\
	\bar{y} = f(\bar{x})\\
	K = \frac{df}{dx}\Big|_{x = \bar{x}}\\
	\text{Linear Proportionality}\\
	y - \bar{y} = K (x-\bar{x})
\end{gathered}
$$

For functions with more than one input we can generalize as:

$$
\begin{gathered}
	y = f(x_1, x_2)\\
	y = f(\bar{x_1},\bar{x_2}) +\\
	\left[\frac{df(x_1-\bar{x_1})}{dx_1}+\frac{df(x_2-\bar{x_2})}{dx_2}\right] + \frac{1}{2!}\\
	\left[\frac{d^2f(x_1-\bar{x_1})^2}{dx_1^2}+ 2\frac{d^2f(x_1-\bar{x_1})(x_2-\bar{x_2})}{dx_1x_2}+ \frac{d^2f(x_2-\bar{x_2})^2}{dx_2^2}\right]\\
	+ \dots\\
	y - \bar{y} = K_1 (x_1-\bar{x_1})+K_2 (x_2-\bar{x_2})\\
	\bar{y} = f(\bar{x_1}, \bar{x_2})\\
	K_1 = \frac{df}{dx_1}\Big|_{x_1 = \bar{x_1}, x_2 = \bar{x_2}}\\
	K_2 = \frac{df}{dx_2}\Big|_{x_1 = \bar{x_1}, x_2 = \bar{x_2}}\\	
	\text{Linear Proportionality}\\
	y - \bar{y} = K_1 (x_1-\bar{x_1})+K_2 (x_2-\bar{x_2})\\
\end{gathered}
$$

For example, if we linearize the next nonlinear equation:

$$
\begin{gathered}
	z = xy \quad 5 \le x \le 7 \quad 10 \le y \le 12 \\
	\text{Region Given Assume Close Values}\\
	\bar{x} = 6 \quad \bar{y} = 11 \quad \bar{z} = \bar{x}\bar{y} = 6 \quad\\
	\text{No High Order Terms - Taylor Series}\\
	z - \bar{z} = a(x-\bar{x}) + b(y-\bar{y})\\
	a = \frac{\delta(xy)}{\delta(x)}\Big|_{x = \bar{x},y=\bar{y}}=\bar{y}=11\\
	b = \frac{\delta(xy)}{\delta(y)}\Big|_{x = \bar{x},y=\bar{y}}=\bar{x}=6\\
	z - 66 = 11(x-6) + 6(y-11)\\
	z = 11x+6y-66\\
	\text{Evaluate Linearization}\\
	z(5,10) = 11x+6y-66 = 55+60-66 = 49\\
	z(5,10) = xy = 50\\
	\text{2 Percent Error}
\end{gathered}
$$

***

**Mechanical System Models**

For mechanical modeling we start by applying Newton's law to components such as springs or dampers.

$$
\begin{gathered}
	\text{Spring Force}\\
	F = kx\\
	\text{Springs in Parallel Force}\\
	F_1 = k_1x \quad F_2 = k_2x\\
	F = F_1 + F_2 = k_1x + k_2x = k_ex\\
	k_e = k_1 + k_2\\
	\text{Springs in Series Force}\\
	F = k_1x_1 = k_2x_2 = F_1 = F_2 \\
	F = k_e (x_1 + x_2)\\
	\frac{F_1}{k_1} +  \frac{F_2}{k_2} = x_1 + x_2\\
	\frac{F}{k_e} = x_1 + x_2\\
	\frac{F}{k_e} =  \frac{F}{k_1} +  \frac{F}{k_2}\\
	\frac{1}{k_e} = \frac{1}{k_1} + \frac{1}{k_2}\\
	k_e = \frac{k_1k_2}{k_1+k_2}\\
	\text{Damper Force}\\
	F = b(\dot{y}-\dot{x})\\
	\text{Damper in Parallel Force}\\
	F_1 = b_1(\dot{y}-\dot{x}) \quad F_2 = b_2(\dot{y}-\dot{x})\\
	F = F_1 + F_2 = b_1(\dot{y}-\dot{x}) + b_2(\dot{y}-\dot{x})\\
	F = b_e(\dot{y}-\dot{x})\\
	b_e = b_1 + b_2\\
	\text{Damper in Series Force}\\
	F = b_1(\dot{y_1}-\dot{x}) = b_2(\dot{y_2}-\dot{x}) = F_1 = F_2 \\
	F = b_e ((\dot{y_1}-\dot{x}) + (\dot{y_2}-\dot{x}))\\
	\frac{F_1}{b_1} +  \frac{F_2}{b_2} = (\dot{y_1}-\dot{x}) + (\dot{y_2}-\dot{x})\\
	\frac{F}{b_e} = (\dot{y_1}-\dot{x}) + (\dot{y_2}-\dot{x})\\
	\frac{F}{b_e} =  \frac{F}{b_1} +  \frac{F}{b_2}\\
	\frac{1}{b_e} = \frac{1}{b_1} + \frac{1}{b_2}\\
	b_e = \frac{b_1b_2}{b_1+b_2}
\end{gathered}
$$

For example, consider the spring-mass-dashpot system on a massless cart. Assume the cart and the system is still at zero conditions but then moves at a constant speed. The input of the system is the displacement of the cart $u(t)$ which remains constant since the system is moving at a constant speed. The output is the displacement of the mass 
$y(t)$ (relative to ground). Note that the force of the dashpot is proportional to $\dot{y}-\dot{u}$ while the force of the spring is proportional to $y-u$.

![Derivative Terms Example](/static/images/notes/ControlExampleWithDerivativesForcingFunct.png)

$$
\begin{gathered}
	F = ma\\
	\left[-k(y - u)\right] + \left[-b(\frac{dy}{dt} - \frac{du}{dt})\right] = (m)\left(\frac{d^2 y}{dt^2}\right)\\
	ku - ky + b\frac{du}{dt} -b\frac{dy}{dt} = (m)\left(\frac{d^2 y}{dt^2}\right)\\
	ku + b\frac{du}{dt} = (m)\left(\frac{d^2 y}{dt^2}\right) + b\frac{dy}{dt} + ky\\
	b\dot{u} + ku = m\ddot{y} + b\dot{y} + ky\\
	G(s) = \frac{bs + k }{ms^2 + bs + k}\\
	b_0\ddot{u} + b\dot{u} + ku = m\ddot{y} + b\dot{y} + ky\\
	b_0\ddot{u} + \frac{b}{m}\dot{u} + \frac{k}{m}u = \ddot{y} + \frac{b}{m}\dot{y} + \frac{k}{m}y\\
	b_0\ddot{u} + b_1\dot{u} + b_2u = \ddot{y} + a_1\dot{y} + a_2y\\
	\beta_0 = b_0 = 0\\
	\beta_1 = b_1 - a_1\beta_0 = \frac{b}{m} - 0 = \frac{b}{m}\\
	\beta_2 = b_2 - a_1\beta_1 - a_2\beta_0 = \frac{k}{m} - (\frac{b}{m})^2\\
	\text{State Variables}\\
	x_n = \dot{x}_{n-1}-\beta_{n-1}u\\
	x_1 = y-\beta_0u = y - 0 = y\\
	x_2 = \dot{x}_1-\beta_1u = \dot{x}_1 - \frac{b}{m}u\\
	\text{First State Equation}\\
	\dot{x}_1 = x_2 + \beta_1u\\
	\dot{x}_1 = x_2 + \frac{b}{m}u\\
	\text{Second State Equation}\\
	\dot{x}_n = -a_nx_1 - \dots - a_1x_n + \beta_n u\\
	\dot{x}_2 = -a_2x_1 - a_1x_2 + \beta_2 u\\
	\dot{x}_2 = -\frac{k}{m}x_1 - \frac{b}{m}x_2 + \left[\frac{k}{m} - (\frac{b}{m})^2\right] u\\
	\text{Output Equation}\\
	y = x_1\\
	\text{Vector Matrix Form}\\
	x = \begin{bmatrix} x_1\\ x_2\end{bmatrix} \quad B = \begin{bmatrix} \frac{b}{m} \\ \frac{k}{m} - (\frac{b}{m})^2 \end{bmatrix}\\
	A = \begin{bmatrix} 0 & 1 \\ -a_2 & -a_1\\ \end{bmatrix} = \begin{bmatrix} 0 & 1 \\ -\frac{k}{m} & -\frac{b}{m}\\ \end{bmatrix}\\
	C = \begin{bmatrix} 1 & 0 \end{bmatrix} \quad D = \beta_0 = 0\\
	y = \begin{bmatrix} 1 & 0 \end{bmatrix}
	\begin{bmatrix} x_1\\ x_2 \end{bmatrix} + B_0u\\
	G(s) = \frac{b_0s^n + b_1s^{n-1}+ \dots + b_{n-1}s+b_n}{s^n + a_1s^{n-1}+ \dots + a_{n-1}s+a_n}\\
	G(s) = \frac{\frac{b}{m}s + \frac{k}{m} }{s^2 + \frac{b}{m}s + \frac{k}{m}}	
\end{gathered} 
$$

For example, obtain the transfer functions at points $x_1$ and $x_2$ of the system:

![Mechanical System Example](/static/images/notes/ControlMechanicalSystemExampleInt.png)

$$
\begin{gathered}
	F = ma\\
	u - k_1x_1 - k_2(x_1 - x_2) - b(\dot{x_1} - \dot{x_2}) = m_1\ddot{x}_1\\
	- k_2(x_2 - x_1) - b(\dot{x_2} - \dot{x_1}) - k_3x_2= m_2\ddot{x}_2\\
	m_1\ddot{x}_1 + k_1x_1 + k_2x_1 + b\dot{x}_1 = k_2x_2 + b\dot{x}_2 + u\\
	m_2\ddot{x}_2 + k_2x_2 + b\dot{x}_2 + k_3x_2 = k_2x_1 + b\dot{x}_1\\
	[m_1s^2 + k_1 + k_2 + bs]X_1(s) = (k_2+bs)X_2(s) + U(s)\\
	[m_2s^2 + k_2 + bs + k_3]X_2(s) = (k_2+bs)X_1(s)\\
	X_2(s) = \frac{(k_2+bs)X_1(s)}{[m_2s^2 + k_2 + bs + k_3]}\\
	a = [m_1s^2 + k_1 + k_2 + bs]\\
	b = [m_2s^2 + k_2 + k_3 + bs]\\
	c = [k_2+bs]\\
	aX_1(s) = c(\frac{cX_1(s)}{b}) + U(s)\\
	abX_1(s) = c^2X_1(s) + bU(s)\\
	abX_1(s) - c^2X_2(s) = bU(s)\\
	[ab - c^2]X_1(s) = bU(s)\\ 
	\frac{X_1(s)}{U(s)} = \frac{b}{ab - c^2}\\
	\frac{X_1(s)}{U(s)} = \frac{m_2s^2 + k_2 + k_3 + bs}{(m_1s^2 + k_1 + k_2 + bs)(m_2s^2 + k_2 + k_3 + bs) - (k_2+bs)^2}\\
	X_2(s) = \frac{c}{b}X_1(s)\\
	X_2(s) = \frac{c}{b} \left[\frac{b}{ab - c^2} U(s)\right]\\
	\frac{X_2(s)}{U(s)} = \frac{c}{ab-c^2}\\
	\frac{X_2(s)}{U(s)} = \frac{k_2+bs}{(m_1s^2 + k_1 + k_2 + bs)(m_2s^2 + k_2 + k_3 + bs) - (k_2+bs)^2}
\end{gathered} 
$$

For example obtain the model of the inverted pendulum system mounted on a motor driven cart. This example is similar to the attitude control system on a spaceship that tries to keep the space booster in a vertical position. The input u(t) is a force applied to the cart, assume first the center of gravity ($x_G, y_G$) is at the geometric center and then assume its at the end of the rod.

![Mechanical System Example](/static/images/notes/ControlPendulumExampleMechanicalpng.png)

$$
\begin{gathered}
	\text{Center of Gravity}\\
	x_G = x + l\sin(\theta)\\
	y_G = l\cos(\theta)\\
	\text{Rotational Motion}\\
	I\ddot{\theta} = (V)(l)(\sin(\theta)) - (H)(l)(\cos(\theta))\\
	H = m\frac{d^2(x+l\sin(\theta))}{dt^2}\\
	V - mg = m\frac{d^2(l\cos(\theta))}{dt^2}\\
	u - H = M\frac{d^2(x)}{dt^2}\\
	\text{Linearization}\\
	\sin(\theta) = \theta \quad \cos(\theta) = 1 \quad \dot{\theta} = 0\\
	I\ddot{\theta} = (V)(l)(\theta) - (H)(l)\\
	H = m(\ddot{\theta} + l\ddot{\theta})\\
	V - mg = 0\\
	\text{Math Model}\\
	(M+m)\ddot{x} + ml\ddot{\theta} = u\\
	(I+ml^2)\ddot{\theta} + ml\ddot{x} = mgl\theta\\\\
	\text{Center of Gravity at End of Rod}\\
	I=0\\
	(M+m)\ddot{x} + ml\ddot{\theta} = u\\
	(0+ml^2)\ddot{\theta} + ml\ddot{x} = mgl\theta\\
	\text{Eliminating} \quad \ddot{x} \text{ and } \ddot{\theta}\\
	M\ddot{x} = u - mg\theta\\
	Ml\ddot{\theta} = (M+m)g\theta -u\\
	\text{Transfer Function}\\
	G(s) = \frac{1}{Mls^2 - Mg - mg}\\
	\text{Poles - Open Loop Unstable}\\
	s = \pm \left(\frac{\sqrt{M+m}}{\sqrt{Ml}}\right) \sqrt{g}\\
	\text{Matrix Representation}\\
	x_1 = \theta \quad x_2 = \dot{\theta} \quad x_3 = x \quad x_4 = \dot{x}\\
	y = \begin{bmatrix} y_1 \\ y_2 \end{bmatrix} = \begin{bmatrix} \theta \\ x \end{bmatrix} = \begin{bmatrix} x_1 \\ x_3 \end{bmatrix}\\
	\text{State Equations}\\
	\dot{x}_1 = x_2\\
	\dot{x}_2 = \frac{M+m}{Ml}gx_1 - \frac{1}{Ml}u\\
	\dot{x}_3 = x_4\\
	\dot{x}_4 = -\frac{m}{M}gx_1 - \frac{1}{M}u\\
	\begin{bmatrix} \dot{x}_1 \\ \dot{x}_2 \\ \dot{x}_3 \\ \dot{x}_4 \end{bmatrix} = 
	\begin{bmatrix} 0 & 1 & 0 & 0 \\ \frac{M+m}{Ml}g & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ -\frac{m}{M}g & 0 & 0 & 0   \end{bmatrix}
	\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4   \end{bmatrix} +
	\begin{bmatrix} 0 \\ - \frac{1}{Ml} \\ 0 \\ \frac{1}{M}   \end{bmatrix} u\\
	\begin{bmatrix} y_1 \\ y_2 \end{bmatrix} = 
	\begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 \end{bmatrix}
	\begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4   \end{bmatrix}
\end{gathered} 
$$

**Electrical System Models**

For electrical modeling we start by applying Kirchhoff's law to components such as resistors, capacitors or inductors.

Basic laws governing electrical circuits are Kirchhoff’s current law and voltage law.
Kirchhoff’s current law (node law) states that the algebraic sum of all currents entering and
leaving a node is zero. (This law can also be stated as follows: The sum of currents enter-
ing a node is equal to the sum of currents leaving the same node.) Kirchhoff’s voltage law
(loop law) states that at any given instant the algebraic sum of the voltages around any loop
in an electrical circuit is zero. (This law can also be stated as follows: The sum of the volt-
age drops is equal to the sum of the voltage rises around a loop.) A mathematical model
of an electrical circuit can be obtained by applying one or both of Kirchhoff’s laws to it.
This section first deals with simple electrical circuits and then treats mathematical
modeling of operational amplifier systems.

LRC Circuit. Consider the electrical circuit shown in Figure 3–7. The circuit con-
sists of an inductance L (henry), a resistance R (ohm), and a capacitance C (farad).
Applying Kirchhoff’s voltage law to the system, we obtain the following equations:

$$
\begin{gathered}
	\text{Spring Force}\\
	F = kx\\
	\text{Springs in Parallel Force}\\
	F_1 = k_1x \quad F_2 = k_2x\\
	F = F_1 + F_2 = k_1x + k_2x = k_ex\\
	k_e = k_1 + k_2\\
	\text{Springs in Series Force}\\
	F = k_1x_1 = k_2x_2 = F_1 = F_2 \\
	F = k_e (x_1 + x_2)\\
	\frac{F_1}{k_1} +  \frac{F_2}{k_2} = x_1 + x_2\\
	\frac{F}{k_e} = x_1 + x_2\\
	\frac{F}{k_e} =  \frac{F}{k_1} +  \frac{F}{k_2}\\
	\frac{1}{k_e} = \frac{1}{k_1} + \frac{1}{k_2}\\
	k_e = \frac{k_1k_2}{k_1+k_2}\\
	\text{Damper Force}\\
	F = b(\dot{y}-\dot{x})\\
	\text{Damper in Parallel Force}\\
	F_1 = b_1(\dot{y}-\dot{x}) \quad F_2 = b_2(\dot{y}-\dot{x})\\
	F = F_1 + F_2 = b_1(\dot{y}-\dot{x}) + b_2(\dot{y}-\dot{x})\\
	F = b_e(\dot{y}-\dot{x})\\
	b_e = b_1 + b_2\\
	\text{Damper in Series Force}\\
	F = b_1(\dot{y_1}-\dot{x}) = b_2(\dot{y_2}-\dot{x}) = F_1 = F_2 \\
	F = b_e ((\dot{y_1}-\dot{x}) + (\dot{y_2}-\dot{x}))\\
	\frac{F_1}{b_1} +  \frac{F_2}{b_2} = (\dot{y_1}-\dot{x}) + (\dot{y_2}-\dot{x})\\
	\frac{F}{b_e} = (\dot{y_1}-\dot{x}) + (\dot{y_2}-\dot{x})\\
	\frac{F}{b_e} =  \frac{F}{b_1} +  \frac{F}{b_2}\\
	\frac{1}{b_e} = \frac{1}{b_1} + \frac{1}{b_2}\\
	b_e = \frac{b_1b_2}{b_1+b_2}
\end{gathered}
$$


**Transient and Steady State**

In practice, the input signal won't be known ahead of time instead being random by nature, meaning that we cannot represent the input analytically, therefore to test the performance of multiple control systems we force a set of values for the input signal known as test-signals to verify and compare that the control systems keep the variables within the wanted range. Commonly used test signals include step, ramp, acceleration, impulse, sinusoidal functions and white noise.

The time response consists of the transient response (initial to end state) and the steady state response (initial to infinity): $c(t) = c_{tr}(t) + c_{ss}(t)$. The most important characteristic of a control system is the absolute stability (stable or unstable). The system is in equilibrium if the output stays the same when there are no disturbances or inputs. 

Linear time-invariant systems are stable if the output eventually comes back to its equilibrium state from any initial conditions, also it is considered critically stable if the oscillations continue to infinity without divergence. In practice most unstable systems won't diverge indefinitely from their mechanical limitations.

Relative stability and steady state error relate to the physical nature of the system as it stores and releases it in a transient response before reaching its steady state, this response usually results in a damped oscillation. The steady state error is the difference from the modeled steady state error and the actual steady state reached (accuracy).

**First Order Systems**

![Control Open System](/static/images/notes/ControlFirstOrderSystemExample.png)

$$
\begin{gathered}
	G(s) = \frac{C(s)}{R(s)} = \frac{1}{Ts+1}\\
	\text{Unit Step Response}\\
	R(s) = \frac{1}{s}\\
	C(s) = \frac{1}{Ts+1}\frac{1}{s}\\
	C(s) = \frac{1}{s}-\frac{T}{Ts+1} = \frac{1}{s}-\frac{1}{s+(1/T)}\\
	c(t) = 1 - e^{-t/T}\\
	t=T \implies c(t) = 1 - e^{-1}= 0.632\\
\end{gathered}
$$

Note that the smaller the time constant $T$ the faster the system response will be, also the slope of the tangent at $t=0$ will be $1/T$, meaning that the initial speed of the response decreases from $1/T$ to $0$ as it approaches infinity.

$$
\begin{gathered}
	\frac{dc(t)}{dt}\Big|_{t=0} = \frac{1}{T}e^{-t/T} = \frac{1}{T}
\end{gathered}
$$

The steady state is reached at infinity but in practice it can be considered within 2% of its limit, in other words we consider the system reaches a steady state after 4 time constants.

The unit ramp response of a first order system will be:

$$
\begin{gathered}
	\text{Unit Ramp Response}\\
	R(s) = \frac{1}{s^2}\\
	C(s) = \frac{1}{Ts+1}\frac{1}{s^2}\\
	C(s) = \frac{1}{s^2}-\frac{T}{s}+\frac{T^2}{Ts+1}\\
	c(t) = 1 - T + Te^{-t/T}\\
	\text{Error Signal}\\
	e(t) = r(t) - c(t) = T(1-e^{-t/T})
\end{gathered}
$$

Note that as $t$ approaches infinity $e^{-t/T}$ approaches zero therefore the error signal approaches $T$. The smaller the time constant $T$ the smaller the error signal (steady state error). 

$$
\begin{gathered}
	\text{Unit Impulse Response}\\
	R(s) = 1\\
	C(s) = \frac{1}{Ts+1}\\
	c(t) = \frac{1}{T}e^{-t/T}\\
\end{gathered}
$$

From the analysis we can note that for linear time invariant systems the response to the derivative of the input is the derivative of the response to the original signal and the response to the integral of the input is the integral og the response to the original signal (integration constant at zero output for initial conditions).

**Second Order Systems**

Considering a servo system we can obtain its response to a step, ramp and impulse input.

![Control Open System](/static/images/notes/ControlServoSecondOrderSystem.png)

$$
\begin{gathered}
	J\ddot{c} + B\dot{c} = T\\
	Js^2C(s) + BsC(s) = T(s)\\
	\frac{C(s)}{T(s)} = \frac{1}{s(Js + B)}\\
	\frac{C(s)}{R(s)} = \frac{K}{Js^2 + Bs +K}\\
	\frac{K/J}{[s+(B/2J)\pm\sqrt{(B/2J)^2-(K/J)}]}\\
	\text{Poles are complex conjugates if}\\
	B^2-4JK < 0\\
	\text{Poles are real if}\\
	B^2-4JK > 0\\
	\text{Attenuation } \sigma\\
	\text{Undamped Natural Frequency } \omega_n\\
	\text{Damping Ratio } \zeta\\
	\frac{K}{J} = \omega_n^2\\
	\frac{B}{J} = 2\zeta \omega_n = 2\sigma\\
	\zeta = \frac{B}{B_c} = \frac{B}{2\sqrt{JK}}\\
	\text{Standard Form}\\
	\frac{C(s)}{R(s)} = \frac{\omega_n^2}{s^2 + 2\zeta \omega_n s + \omega_n^2}\\
\end{gathered}
$$

The poles are complex conjugates if $0<\zeta<1$ and the system will be underdamped with an oscillatory pattern. If $\zeta = 0$ the response will continue oscillating indefinitely. If $\zeta = 1$ the system will be critically damped. If $\zeta < 1$ the system will be overdamped.

$$
\begin{gathered}
	\text{1 Step Unit Response Underdamped}\\
	\text{Damped natural frequency}\\
	\omega_d = \omega_n\sqrt{1-\zeta^2}\\
	\frac{C(s)}{R(s)} = \frac{\omega_n^2}{(s + \zeta \omega_n + j\omega_d)(s + \zeta \omega_n - j\omega_d)}\\
	C(s) = \frac{\omega_n^2}{(s^2 + 2\zeta \omega_n s + \omega_n^2)s}\\
	C(s) = \frac{1}{s} - \frac{s+2\zeta \omega_n}{(s+\zeta\omega_n)^2+\omega_d^2} - \frac{\zeta \omega_n}{(s+\zeta\omega_n)^2+\omega_d^2}\\
	c(t) = 1 - e^{-\zeta\omega_n t}(\cos(\omega_n t)  + \frac{\zeta}{\sqrt{1-\zeta^2}}\sin(\omega_n t))\\
	\text{Error signal}\\
	e(t) = r(t) - c(t)\\
	e(t) = e^{-\zeta\omega_n t}(\cos(\omega_n t)  + \frac{\zeta}{\sqrt{1-\zeta^2}}\sin(\omega_n t))\\
	\text{If damping ratio is zero then}\\
	c(t) = 1-\cos(\omega_n t)\\
	\text{2 Step Unit Response Critically Damped}\\
	C(s) = \frac{\omega_n^2}{(s+\omega_n)^2s}\\
	c(t) = 1 - e^{-\omega_n t}(1+\omega_n t)\\
	\text{3 Step Unit Response Overdamped}\\
	C(s) = \frac{\omega_n^2}{(s + \zeta \omega_n \pm \omega_n \sqrt{\zeta^2 - 1})s}\\
	c(t) = 1 + \frac{e^{-(\zeta + \sqrt{\zeta^2 - 1})\omega_n t}}{2\sqrt{\zeta^2 - 1}(\zeta + \sqrt{\zeta^2 - 1})}\\
	\text{Greatly overdamped can ignore one pole}\\
	c(t) = 1 - e^{-(\zeta + \sqrt{\zeta^2 - 1})\omega_n t}\\
\end{gathered}
$$

We can see the unit response curves c(t) for multiple values of $\zeta$ with the dimensionless abscissa $\omega_n t$. Note that if $\zeta$ is the same and $\omega_n$ changes (same relative stability) the model will have the same overshoot and oscillatory pattern. From the curves we conclude that underdamped $\zeta$ values of 0.5 to 0.8 get to a stable state quicker than critically damped or overdamped systems. If the system doesn't have oscillations then critically damped systems will be the quickest.

***

TODO:

1. Finish Laplace Properties Table
2. Finish Matrix operations (sum, substraction, inverse, product, etc)






















